{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe592c04",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to generate various ratings/rankings features for the teams in our dataset. We will generate elo ratings, pi ratings, rpi ratings, as well as league rankings, and use a neural network to create embeddings for the home and away teams which will serve as a ranking of the home strength and away strength of the home and away teams respectively. \n",
    "\n",
    "In order to speed up the calculations we will be creating these features for the subset of top European leagues. This will give us more than enough games to generate accurate ratings and give us a large training set to work with. We will be conducting an EDA on the generated features and will be comparing them using a single variable logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec902870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, brier_score_loss, log_loss\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "import optuna\n",
    "import pickle\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e2988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_opt.csv\")\n",
    "df = df[df['season'] != 2013]\n",
    "\n",
    "features = ['home_win', 'away_win', 'pi_diff','gd_diff', \n",
    "            'elo_gls_diff', 'home_ip_scaled', 'away_ip_scaled',\n",
    "       'home_ip', 'away_ip', 'ip_diff', 'season']\n",
    "\n",
    "df = df[features].astype(float)\n",
    "\n",
    "train = df[df['season'] != 2022.]\n",
    "test = df[df['season'] == 2022.]\n",
    "\n",
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66d5a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimiser:\n",
    "    \n",
    "    def __init__(self, df, model_name, verbosity=False):\n",
    "        self.df = df\n",
    "        self.model_name = model_name\n",
    "        self.verbosity = verbosity\n",
    "        \n",
    "        if self.model_name == \"XGB\":\n",
    "            self.model = XGBClassifier()\n",
    "        elif self.model_name == \"LGBM\":\n",
    "            self.model = LGBMClassifier()\n",
    "        elif self.model_name == \"GBC\":\n",
    "            self.model = GradientBoostingClassifier()\n",
    "        elif self.model_name == \"CAT\":\n",
    "            self.model = CatBoostClassifier(verbose = verbosity)\n",
    "            \n",
    "    def process_df(self, df):\n",
    "        \n",
    "        df = df.astype(float)\n",
    "        df = df[df['season'] != 2013]\n",
    "        df = df.dropna()\n",
    "        train = df[df['season'] != 2022.]\n",
    "        test = df[df['season'] == 2022.]\n",
    "        \n",
    "        X_train = train.drop(['home_win', 'away_win', 'season'], axis=1)\n",
    "        X_test = test.drop(['home_win', 'away_win', 'season'], axis=1)\n",
    "        y_train = train['home_win']\n",
    "        y_test = test['home_win']\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def objective(self, trial):\n",
    "\n",
    "\n",
    "        if self.model_name == \"XGB\":\n",
    "            params = {\n",
    "                \n",
    "            'booster': 'gbtree',\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "            'scale_pos_weight': (0.45/0.55),\n",
    "            'subsample': trial.suggest_float('subsample', 0.2, 1.0, step=0.1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0, step=0.1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 10, log=True),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 10, log=True),\n",
    "            'gamma': trial.suggest_float('gamma', 1e-5, 10, log=True),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10)\n",
    "                \n",
    "        }\n",
    "            model = XGBClassifier(**params)\n",
    "\n",
    "        elif self.model_name == \"LGBM\":\n",
    "            \n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "                'subsample': trial.suggest_float('subsample', 0.2, 1.0, step=0.1),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0, step=0.1),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 10, log=True),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 10, log=True),\n",
    "                'min_child_weight': trial.suggest_float('min_child_weight', 1e-5, 10, log=True)\n",
    "            }\n",
    "\n",
    "            model = LGBMClassifier(**params)\n",
    "            \n",
    "        elif self.model_name == \"GBC\":\n",
    "            \n",
    "            params = {\n",
    "                'loss': 'deviance',\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "                'subsample': trial.suggest_float('subsample', 0.2, 1.0, step=0.1),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "                'random_state': 42\n",
    "            }\n",
    "\n",
    "            model = GradientBoostingClassifier(**params)\n",
    "            \n",
    "        elif self.model_name == \"CAT\":\n",
    "\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 100, 1000, step=100),\n",
    "                'depth': trial.suggest_int('depth', 1, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "                'random_seed': 42,\n",
    "                'loss_function': 'Logloss',\n",
    "                'eval_metric': 'Accuracy',\n",
    "                'bootstrap_type': 'Bayesian',\n",
    "                'subsample': trial.suggest_float('subsample', 0.2, 1.0, step=0.1),\n",
    "                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.2, 1.0, step=0.1),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-5, 10, log=True),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "                'verbose': self.verbosity\n",
    "            }\n",
    "\n",
    "            model = CatBoostClassifier(**params)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = self.process_df(self.df)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "        auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "\n",
    "        return auc\n",
    "\n",
    "    def optimise(self):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.process_df(self.df)\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(self.objective, n_trials=100, show_progress_bar=self.verbosity)\n",
    "        best_params = study.best_params\n",
    "        \n",
    "        if self.model_name == \"XGB\":\n",
    "            best_model = XGBClassifier(**best_params)\n",
    "            \n",
    "        elif  self.model_name == \"LGBM\":\n",
    "            best_model = LGBMClassifier(**best_params)\n",
    "            \n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        results = cross_val_score(self.model, self.X_train, self.y_train, cv=kfold, verbose=self.verbosity)\n",
    "        \n",
    "        print(\"Results of K-fold CV for\", self.model, \":\", results)\n",
    "        print(\"Mean:\", results.mean())\n",
    "        print(\"Std:\", results.std())\n",
    "\n",
    "        best_model.fit(self.X_train, self.y_train, \n",
    "                       early_stopping_rounds=1000, \n",
    "                       eval_set=[(self.X_test, self.y_test)],\n",
    "                       verbose=self.verbosity)\n",
    "\n",
    "        y_pred_test = best_model.predict(self.X_test)\n",
    "        y_prob_test = best_model.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "        test_accuracy = accuracy_score(self.y_test, y_pred_test)\n",
    "        test_f1 = f1_score(self.y_test, y_pred_test)\n",
    "\n",
    "        test_roc_auc_score = roc_auc_score(self.y_test, y_prob_test)\n",
    "        test_precision_score = precision_score(self.y_test, y_pred_test)\n",
    "\n",
    "        print(\"Best Hyperparameters:\", best_params)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        print(\"Test F1 Score:\", test_f1)\n",
    "        print(\"Test AUC:\", test_roc_auc_score)\n",
    "        print(\"Test Precision Score:\", test_precision_score)\n",
    "\n",
    "        return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afa6772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:41:20,628] A new study created in memory with name: no-name-c3500b8b-184c-48f9-b29c-39f7749503e2\n",
      "[I 2023-07-05 17:41:20,711] Trial 0 finished with value: 0.7377686523024926 and parameters: {'max_depth': 1, 'learning_rate': 0.05050775271354401, 'n_estimators': 200, 'subsample': 0.5, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 3.866367189790053e-05, 'reg_alpha': 0.96847707935293, 'min_child_weight': 0.02994246844842017}. Best is trial 0 with value: 0.7377686523024926.\n",
      "[I 2023-07-05 17:41:20,855] Trial 1 finished with value: 0.7379349387410225 and parameters: {'max_depth': 1, 'learning_rate': 0.03509850493836054, 'n_estimators': 400, 'subsample': 0.4, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.00035244351487782335, 'reg_alpha': 0.037231809764158935, 'min_child_weight': 5.468859580600358e-05}. Best is trial 1 with value: 0.7379349387410225.\n",
      "[I 2023-07-05 17:41:21,120] Trial 2 finished with value: 0.7540082805238699 and parameters: {'max_depth': 8, 'learning_rate': 0.014458070759009106, 'n_estimators': 200, 'subsample': 0.4, 'colsample_bytree': 0.5, 'reg_lambda': 0.001445055217274129, 'reg_alpha': 0.0006735529508843517, 'min_child_weight': 0.006559609350985166}. Best is trial 2 with value: 0.7540082805238699.\n",
      "[I 2023-07-05 17:41:21,496] Trial 3 finished with value: 0.7651484579636672 and parameters: {'max_depth': 9, 'learning_rate': 0.031140498036309666, 'n_estimators': 300, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_lambda': 0.011181254324115025, 'reg_alpha': 0.5307816891699563, 'min_child_weight': 0.9675842055716395}. Best is trial 3 with value: 0.7651484579636672.\n",
      "[I 2023-07-05 17:41:22,452] Trial 4 finished with value: 0.762751161808196 and parameters: {'max_depth': 6, 'learning_rate': 0.07305192875962203, 'n_estimators': 900, 'subsample': 0.7, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 3.4759754641373046, 'reg_alpha': 0.38111767719493395, 'min_child_weight': 1.6975452431041584}. Best is trial 3 with value: 0.7651484579636672.\n",
      "[I 2023-07-05 17:41:23,165] Trial 5 finished with value: 0.762336797634136 and parameters: {'max_depth': 5, 'learning_rate': 0.011830510498646548, 'n_estimators': 700, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 0.009258203211890343, 'reg_alpha': 0.0026807595650933545, 'min_child_weight': 0.15246445236648273}. Best is trial 3 with value: 0.7651484579636672.\n",
      "[I 2023-07-05 17:41:23,557] Trial 6 finished with value: 0.7459525137304605 and parameters: {'max_depth': 3, 'learning_rate': 0.005703873467156212, 'n_estimators': 700, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_lambda': 0.003987339936859842, 'reg_alpha': 0.00019223481558251637, 'min_child_weight': 0.01851006696102231}. Best is trial 3 with value: 0.7651484579636672.\n",
      "[I 2023-07-05 17:41:24,187] Trial 7 finished with value: 0.7500643852978454 and parameters: {'max_depth': 10, 'learning_rate': 0.0016652752096064333, 'n_estimators': 400, 'subsample': 0.4, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 0.00026210223083086365, 'reg_alpha': 0.018493856928768378, 'min_child_weight': 0.06790012235105038}. Best is trial 3 with value: 0.7651484579636672.\n",
      "[I 2023-07-05 17:41:24,362] Trial 8 finished with value: 0.7418149556400507 and parameters: {'max_depth': 4, 'learning_rate': 0.005706260703349193, 'n_estimators': 200, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_lambda': 5.203332153267282e-05, 'reg_alpha': 2.4744164289245323e-05, 'min_child_weight': 1.0302660542692357e-05}. Best is trial 3 with value: 0.7651484579636672.\n",
      "[I 2023-07-05 17:41:25,500] Trial 9 finished with value: 0.7474741022391214 and parameters: {'max_depth': 8, 'learning_rate': 0.003855908586189815, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.005666806670053974, 'reg_alpha': 0.0014934897831196065, 'min_child_weight': 1.5926398168427597e-05}. Best is trial 3 with value: 0.7651484579636672.\n",
      "[I 2023-07-05 17:41:26,170] Trial 10 finished with value: 0.7628241656104774 and parameters: {'max_depth': 10, 'learning_rate': 0.09949721382521169, 'n_estimators': 500, 'subsample': 1.0, 'colsample_bytree': 0.2, 'reg_lambda': 0.10149639460484333, 'reg_alpha': 3.0421497430858477, 'min_child_weight': 3.4098888297571386}. Best is trial 3 with value: 0.7651484579636672.\n",
      "[I 2023-07-05 17:41:26,776] Trial 11 finished with value: 0.7695232784114914 and parameters: {'max_depth': 10, 'learning_rate': 0.08032714625820403, 'n_estimators': 500, 'subsample': 1.0, 'colsample_bytree': 0.2, 'reg_lambda': 0.1124882497873281, 'reg_alpha': 9.81608439526856, 'min_child_weight': 8.04285972369793}. Best is trial 11 with value: 0.7695232784114914.\n",
      "[I 2023-07-05 17:41:27,354] Trial 12 finished with value: 0.7701316434305028 and parameters: {'max_depth': 8, 'learning_rate': 0.028873225838778653, 'n_estimators': 400, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.08486419993066345, 'reg_alpha': 7.179905265413471, 'min_child_weight': 5.003599422391484}. Best is trial 12 with value: 0.7701316434305028.\n",
      "[I 2023-07-05 17:41:28,117] Trial 13 finished with value: 0.7578274609209972 and parameters: {'max_depth': 7, 'learning_rate': 0.023625746893511008, 'n_estimators': 600, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.21367471250460857, 'reg_alpha': 9.058612341404428, 'min_child_weight': 6.331237611050288}. Best is trial 12 with value: 0.7701316434305028.\n",
      "[I 2023-07-05 17:41:28,815] Trial 14 finished with value: 0.7660163920574568 and parameters: {'max_depth': 8, 'learning_rate': 0.05191819593062288, 'n_estimators': 500, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.2, 'reg_lambda': 0.10748930836580643, 'reg_alpha': 8.951813077859768, 'min_child_weight': 9.357715539084243}. Best is trial 12 with value: 0.7701316434305028.\n",
      "[I 2023-07-05 17:41:29,729] Trial 15 finished with value: 0.7708234896493451 and parameters: {'max_depth': 10, 'learning_rate': 0.020629209792588078, 'n_estimators': 700, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 1.0240937105466028, 'reg_alpha': 0.0957115332607315, 'min_child_weight': 0.6450793571484854}. Best is trial 15 with value: 0.7708234896493451.\n",
      "[I 2023-07-05 17:41:30,625] Trial 16 finished with value: 0.7692140261934939 and parameters: {'max_depth': 7, 'learning_rate': 0.01723657486991282, 'n_estimators': 700, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_lambda': 5.8455226600394825, 'reg_alpha': 0.09474968327608095, 'min_child_weight': 0.6363764390639052}. Best is trial 15 with value: 0.7708234896493451.\n",
      "[I 2023-07-05 17:41:31,931] Trial 17 finished with value: 0.7712513730460497 and parameters: {'max_depth': 9, 'learning_rate': 0.023172097632852218, 'n_estimators': 1000, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 1.1601504437595398, 'reg_alpha': 0.145460017562233, 'min_child_weight': 0.4394728309379978}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:33,247] Trial 18 finished with value: 0.7685434727503168 and parameters: {'max_depth': 9, 'learning_rate': 0.009491131749044217, 'n_estimators': 1000, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_lambda': 2.2143007747326684, 'reg_alpha': 0.10984994752246545, 'min_child_weight': 0.2797254895292191}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:34,369] Trial 19 finished with value: 0.7644822982678496 and parameters: {'max_depth': 6, 'learning_rate': 0.017874161964068547, 'n_estimators': 1000, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.5, 'reg_lambda': 1.0880561089585774, 'reg_alpha': 0.0072336499783940186, 'min_child_weight': 0.4550563603003557}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:35,448] Trial 20 finished with value: 0.7609470215462611 and parameters: {'max_depth': 9, 'learning_rate': 0.023557046571375584, 'n_estimators': 800, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.7503841324577909, 'reg_alpha': 0.12218333369559133, 'min_child_weight': 0.004604471753527984}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:36,469] Trial 21 finished with value: 0.768857794676806 and parameters: {'max_depth': 9, 'learning_rate': 0.03625331503443761, 'n_estimators': 800, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 0.44100327970310815, 'reg_alpha': 1.124634764419389, 'min_child_weight': 2.126748825170871}. Best is trial 17 with value: 0.7712513730460497.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:41:36,670] Trial 22 finished with value: 0.7493745669623997 and parameters: {'max_depth': 7, 'learning_rate': 0.018441525014402223, 'n_estimators': 100, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 7.794644118140835, 'reg_alpha': 0.2900871827292046, 'min_child_weight': 1.4599401788169115}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:37,509] Trial 23 finished with value: 0.7706213772708069 and parameters: {'max_depth': 10, 'learning_rate': 0.027003771608544776, 'n_estimators': 600, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.04403471800866459, 'reg_alpha': 1.7374797245443323, 'min_child_weight': 0.1774082686437504}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:38,397] Trial 24 finished with value: 0.769453316434305 and parameters: {'max_depth': 10, 'learning_rate': 0.04381156880021076, 'n_estimators': 600, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_lambda': 1.414890007055601, 'reg_alpha': 1.4892511921211862, 'min_child_weight': 0.2223743659920101}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:39,526] Trial 25 finished with value: 0.7614533164343051 and parameters: {'max_depth': 10, 'learning_rate': 0.009473284485640785, 'n_estimators': 800, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_lambda': 0.030771781323791225, 'reg_alpha': 0.03932802827495422, 'min_child_weight': 0.1077680451976973}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:40,724] Trial 26 finished with value: 0.7708316011829319 and parameters: {'max_depth': 9, 'learning_rate': 0.024656718879286343, 'n_estimators': 900, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.43148977352455314, 'reg_alpha': 0.24255353760250412, 'min_child_weight': 0.49828184783029444}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:41,918] Trial 27 finished with value: 0.7682805238698776 and parameters: {'max_depth': 9, 'learning_rate': 0.02169486811859797, 'n_estimators': 900, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.7, 'reg_lambda': 0.44418877975535215, 'reg_alpha': 0.29282380544575487, 'min_child_weight': 0.654514508415258}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:42,470] Trial 28 finished with value: 0.7579373046049852 and parameters: {'max_depth': 3, 'learning_rate': 0.01297815630042542, 'n_estimators': 1000, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 9.507709362373967, 'reg_alpha': 0.010675748165455865, 'min_child_weight': 0.05741278159367295}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:43,495] Trial 29 finished with value: 0.7616817912970004 and parameters: {'max_depth': 7, 'learning_rate': 0.0540416802124692, 'n_estimators': 900, 'subsample': 0.7, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 2.1842024811968823, 'reg_alpha': 0.7247188677478192, 'min_child_weight': 0.031210968418918787}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:44,531] Trial 30 finished with value: 0.7664513730460499 and parameters: {'max_depth': 8, 'learning_rate': 0.040327186577304906, 'n_estimators': 800, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_lambda': 0.5945570955797408, 'reg_alpha': 0.18364125338633785, 'min_child_weight': 0.49516482351526475}. Best is trial 17 with value: 0.7712513730460497.\n",
      "[I 2023-07-05 17:41:45,369] Trial 31 finished with value: 0.7715663709336713 and parameters: {'max_depth': 10, 'learning_rate': 0.029383063382430796, 'n_estimators': 600, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.2866855909465549, 'reg_alpha': 2.1629528842145294, 'min_child_weight': 0.29319534385555374}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:46,328] Trial 32 finished with value: 0.7685191381495564 and parameters: {'max_depth': 9, 'learning_rate': 0.03209053019729754, 'n_estimators': 700, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.34359371289519064, 'reg_alpha': 0.04841568565960889, 'min_child_weight': 2.0527593892628686}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:47,614] Trial 33 finished with value: 0.7693275876637093 and parameters: {'max_depth': 9, 'learning_rate': 0.022232785149502644, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 1.5406223064314897, 'reg_alpha': 0.5825934876817801, 'min_child_weight': 0.3378464371556216}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:48,832] Trial 34 finished with value: 0.7663736375158428 and parameters: {'max_depth': 10, 'learning_rate': 0.03462114997878324, 'n_estimators': 900, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.24731118859181328, 'reg_alpha': 0.193432085089902, 'min_child_weight': 0.953637987443228}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:49,155] Trial 35 finished with value: 0.7377253907900296 and parameters: {'max_depth': 1, 'learning_rate': 0.014786384120088796, 'n_estimators': 800, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_lambda': 0.8990597356520649, 'reg_alpha': 0.05348292645527793, 'min_child_weight': 1.0539150776097177}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:49,925] Trial 36 finished with value: 0.7705274186734263 and parameters: {'max_depth': 8, 'learning_rate': 0.055192583800677736, 'n_estimators': 600, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 4.947188497909875, 'reg_alpha': 0.5085714869050081, 'min_child_weight': 0.08780857185646626}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:50,930] Trial 37 finished with value: 0.7710056611744824 and parameters: {'max_depth': 9, 'learning_rate': 0.027718977872476677, 'n_estimators': 700, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_lambda': 3.5368719092194594, 'reg_alpha': 3.2443913909576962, 'min_child_weight': 3.396509951818432}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:52,144] Trial 38 finished with value: 0.7710702154626109 and parameters: {'max_depth': 6, 'learning_rate': 0.029841801568031817, 'n_estimators': 1000, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 2.3463420203058507, 'reg_alpha': 3.536852747580651, 'min_child_weight': 3.0686816893487143}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:53,187] Trial 39 finished with value: 0.7705923109421209 and parameters: {'max_depth': 5, 'learning_rate': 0.02995885633615467, 'n_estimators': 1000, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 3.3812661492846643, 'reg_alpha': 4.257590902593397, 'min_child_weight': 3.135243401078658}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:53,372] Trial 40 finished with value: 0.7541137304604985 and parameters: {'max_depth': 2, 'learning_rate': 0.04138936861369312, 'n_estimators': 300, 'subsample': 0.5, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 2.6521479066452476, 'reg_alpha': 3.015223309632862, 'min_child_weight': 3.6392014681257576}. Best is trial 31 with value: 0.7715663709336713.\n",
      "[I 2023-07-05 17:41:54,453] Trial 41 finished with value: 0.7720807773553021 and parameters: {'max_depth': 6, 'learning_rate': 0.026786081304135383, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 4.765918972191135, 'reg_alpha': 1.7331804357315346, 'min_child_weight': 1.988333093007995}. Best is trial 41 with value: 0.7720807773553021.\n",
      "[I 2023-07-05 17:41:55,444] Trial 42 finished with value: 0.7708626953950148 and parameters: {'max_depth': 5, 'learning_rate': 0.02833601181306143, 'n_estimators': 1000, 'subsample': 0.4, 'colsample_bytree': 0.8, 'reg_lambda': 5.397121094665152, 'reg_alpha': 1.4872838849138854, 'min_child_weight': 1.849515248977335}. Best is trial 41 with value: 0.7720807773553021.\n",
      "[I 2023-07-05 17:41:56,544] Trial 43 finished with value: 0.7680980143641741 and parameters: {'max_depth': 6, 'learning_rate': 0.04517087861387623, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7, 'reg_lambda': 2.9831700908306766, 'reg_alpha': 2.83758263590068, 'min_child_weight': 3.280872288665339}. Best is trial 41 with value: 0.7720807773553021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:41:57,277] Trial 44 finished with value: 0.7719337558090409 and parameters: {'max_depth': 4, 'learning_rate': 0.03498711140630237, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7, 'reg_lambda': 9.207977574869663, 'reg_alpha': 1.103292253381097, 'min_child_weight': 1.1933812634840795}. Best is trial 41 with value: 0.7720807773553021.\n",
      "[I 2023-07-05 17:41:58,056] Trial 45 finished with value: 0.7707714406421632 and parameters: {'max_depth': 4, 'learning_rate': 0.05800106801961582, 'n_estimators': 1000, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'reg_lambda': 8.788406947618515, 'reg_alpha': 0.8834086200970356, 'min_child_weight': 1.106565369985108}. Best is trial 41 with value: 0.7720807773553021.\n",
      "[I 2023-07-05 17:41:58,750] Trial 46 finished with value: 0.7718732572877058 and parameters: {'max_depth': 4, 'learning_rate': 0.038039043736443394, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.2985578808005391, 'reg_alpha': 0.5187308009948188, 'min_child_weight': 9.350343225832694}. Best is trial 41 with value: 0.7720807773553021.\n",
      "[I 2023-07-05 17:41:59,479] Trial 47 finished with value: 0.7674727503168568 and parameters: {'max_depth': 4, 'learning_rate': 0.07108256102531861, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 1.0, 'reg_lambda': 1.359468472498819, 'reg_alpha': 0.7862284553094685, 'min_child_weight': 8.532335300368377}. Best is trial 41 with value: 0.7720807773553021.\n",
      "[I 2023-07-05 17:42:00,133] Trial 48 finished with value: 0.7723079002957329 and parameters: {'max_depth': 4, 'learning_rate': 0.03688244346838384, 'n_estimators': 800, 'subsample': 0.2, 'colsample_bytree': 1.0, 'reg_lambda': 4.879505533078039, 'reg_alpha': 0.47394457053712785, 'min_child_weight': 5.262582529721263}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:00,591] Trial 49 finished with value: 0.7695094212082805 and parameters: {'max_depth': 3, 'learning_rate': 0.03414237501995315, 'n_estimators': 800, 'subsample': 0.2, 'colsample_bytree': 1.0, 'reg_lambda': 5.371436361152858, 'reg_alpha': 0.5080928583034721, 'min_child_weight': 5.7572542924833225}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:01,233] Trial 50 finished with value: 0.7697142374313479 and parameters: {'max_depth': 4, 'learning_rate': 0.06289551794704436, 'n_estimators': 800, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 4.111073439299426, 'reg_alpha': 1.4775550493287726, 'min_child_weight': 9.116206466975834}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:01,746] Trial 51 finished with value: 0.7714477397549641 and parameters: {'max_depth': 3, 'learning_rate': 0.03872230012396502, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 9.670439965499764, 'reg_alpha': 0.9148894305752322, 'min_child_weight': 1.2476480338597244}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:02,257] Trial 52 finished with value: 0.7722004224757075 and parameters: {'max_depth': 3, 'learning_rate': 0.04808340656909883, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 9.315956372336963, 'reg_alpha': 0.3633503889433697, 'min_child_weight': 1.5503596170690397}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:02,702] Trial 53 finished with value: 0.7707667089142375 and parameters: {'max_depth': 3, 'learning_rate': 0.04899757709197933, 'n_estimators': 800, 'subsample': 0.30000000000000004, 'colsample_bytree': 1.0, 'reg_lambda': 9.848112726720982, 'reg_alpha': 5.544715094011338, 'min_child_weight': 5.338738165992586}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:03,121] Trial 54 finished with value: 0.7678070130967469 and parameters: {'max_depth': 2, 'learning_rate': 0.046176751618693376, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.9799958825505226, 'reg_alpha': 0.37118797529030034, 'min_child_weight': 9.820546865088211}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:03,469] Trial 55 finished with value: 0.7694046472327841 and parameters: {'max_depth': 2, 'learning_rate': 0.0877931093842264, 'n_estimators': 700, 'subsample': 0.4, 'colsample_bytree': 1.0, 'reg_lambda': 4.917703607168825, 'reg_alpha': 2.011243924363778, 'min_child_weight': 2.3857797035895474}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:03,848] Trial 56 finished with value: 0.7689933248838191 and parameters: {'max_depth': 4, 'learning_rate': 0.06972693216137552, 'n_estimators': 500, 'subsample': 0.4, 'colsample_bytree': 1.0, 'reg_lambda': 0.7717030603072185, 'reg_alpha': 0.3520150865274347, 'min_child_weight': 4.406961001420397}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:04,793] Trial 57 finished with value: 0.77012927756654 and parameters: {'max_depth': 5, 'learning_rate': 0.03572373220995386, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.6507480926149376, 'reg_alpha': 5.603326498284875, 'min_child_weight': 1.646808672517307}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:05,594] Trial 58 finished with value: 0.7679587663709335 and parameters: {'max_depth': 5, 'learning_rate': 0.06157239409267103, 'n_estimators': 800, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7, 'reg_lambda': 3.4565369101308154, 'reg_alpha': 0.9992656360752704, 'min_child_weight': 5.996087257457585}. Best is trial 48 with value: 0.7723079002957329.\n",
      "[I 2023-07-05 17:42:06,315] Trial 59 finished with value: 0.7727810730882974 and parameters: {'max_depth': 4, 'learning_rate': 0.046033547680538016, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 6.171342051616281, 'reg_alpha': 0.5236129356011417, 'min_child_weight': 0.7644551149591239}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:07,043] Trial 60 finished with value: 0.7722294888043937 and parameters: {'max_depth': 4, 'learning_rate': 0.04881619966666487, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 5.246774285576878, 'reg_alpha': 0.4721000881305763, 'min_child_weight': 0.8416772666576555}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:07,764] Trial 61 finished with value: 0.7714406421630756 and parameters: {'max_depth': 4, 'learning_rate': 0.049298483747572897, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 5.946161060375443, 'reg_alpha': 0.46025287483023275, 'min_child_weight': 1.8898322157679626}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:08,475] Trial 62 finished with value: 0.7719989860583016 and parameters: {'max_depth': 4, 'learning_rate': 0.04171427817733094, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 5.382433775154694, 'reg_alpha': 0.2664271918137162, 'min_child_weight': 0.8373464088798704}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:09,190] Trial 63 finished with value: 0.77037127165188 and parameters: {'max_depth': 4, 'learning_rate': 0.07678445752882515, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'reg_lambda': 6.486940710932802, 'reg_alpha': 0.22980793784504147, 'min_child_weight': 0.727000721581433}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:09,642] Trial 64 finished with value: 0.7714058301647656 and parameters: {'max_depth': 3, 'learning_rate': 0.04446083960436658, 'n_estimators': 800, 'subsample': 0.4, 'colsample_bytree': 1.0, 'reg_lambda': 3.0786927860577187, 'reg_alpha': 0.07497785266886134, 'min_child_weight': 0.7908823862714223}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:10,615] Trial 65 finished with value: 0.7687868187579214 and parameters: {'max_depth': 5, 'learning_rate': 0.05398213636511695, 'n_estimators': 1000, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 6.462065427389339, 'reg_alpha': 0.14149312013594598, 'min_child_weight': 0.1876002442632812}. Best is trial 59 with value: 0.7727810730882974.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:42:11,695] Trial 66 finished with value: 0.7572941275876638 and parameters: {'max_depth': 6, 'learning_rate': 0.08732771554300779, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.8, 'reg_lambda': 2.2347037674842185, 'reg_alpha': 1.118817984485216, 'min_child_weight': 1.2476580812988047}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:12,371] Trial 67 finished with value: 0.7717316434305027 and parameters: {'max_depth': 4, 'learning_rate': 0.04047840412612542, 'n_estimators': 800, 'subsample': 0.30000000000000004, 'colsample_bytree': 1.0, 'reg_lambda': 4.174249789021216, 'reg_alpha': 0.2679531577859429, 'min_child_weight': 0.38528739490160513}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:13,347] Trial 68 finished with value: 0.7654367553865653 and parameters: {'max_depth': 5, 'learning_rate': 0.06616894060264919, 'n_estimators': 1000, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 7.413339593042412, 'reg_alpha': 0.1632250597273395, 'min_child_weight': 0.6685151436187262}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:13,855] Trial 69 finished with value: 0.7691008027038446 and parameters: {'max_depth': 3, 'learning_rate': 0.025309782874046588, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 0.606532663582476, 'reg_alpha': 0.6966177450302935, 'min_child_weight': 0.2986024921055287}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:14,307] Trial 70 finished with value: 0.7655087452471483 and parameters: {'max_depth': 2, 'learning_rate': 0.03410863271524678, 'n_estimators': 1000, 'subsample': 0.4, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.0564485965078967, 'reg_alpha': 0.3387881534499464, 'min_child_weight': 1.4334521326424858}. Best is trial 59 with value: 0.7727810730882974.\n",
      "[I 2023-07-05 17:42:15,024] Trial 71 finished with value: 0.7733455006337135 and parameters: {'max_depth': 4, 'learning_rate': 0.03831628585040062, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 1.6589792192011186, 'reg_alpha': 0.5750262101450965, 'min_child_weight': 5.16458108325335}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:15,529] Trial 72 finished with value: 0.77197127165188 and parameters: {'max_depth': 3, 'learning_rate': 0.049163822416623176, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 4.375325955246831, 'reg_alpha': 1.2463324862705216, 'min_child_weight': 2.271046046898395}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:16,010] Trial 73 finished with value: 0.7713997465145753 and parameters: {'max_depth': 3, 'learning_rate': 0.049947389978421124, 'n_estimators': 800, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 1.9629168579188168, 'reg_alpha': 1.8420499772455645, 'min_child_weight': 2.412987615524284}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:16,722] Trial 74 finished with value: 0.7697264047317278 and parameters: {'max_depth': 4, 'learning_rate': 0.05816652955673341, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 4.34438271971927, 'reg_alpha': 0.7192713611538871, 'min_child_weight': 5.053292263878167}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:17,171] Trial 75 finished with value: 0.7701978876214618 and parameters: {'max_depth': 3, 'learning_rate': 0.04201707595232171, 'n_estimators': 800, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 2.870475337025171, 'reg_alpha': 0.0924210036892923, 'min_child_weight': 2.1493474566971873}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:18,063] Trial 76 finished with value: 0.7675991550485848 and parameters: {'max_depth': 5, 'learning_rate': 0.04976089960287377, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 6.333668100463501, 'reg_alpha': 0.4151560550737964, 'min_child_weight': 4.001514844283154}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:18,615] Trial 77 finished with value: 0.7710225602027884 and parameters: {'max_depth': 3, 'learning_rate': 0.059317000328617274, 'n_estimators': 1000, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_lambda': 4.0166765621496685, 'reg_alpha': 0.18616196080146988, 'min_child_weight': 0.8713099294593434}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:19,036] Trial 78 finished with value: 0.7638320236586396 and parameters: {'max_depth': 2, 'learning_rate': 0.030673177033371593, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.645880381660421, 'reg_alpha': 0.281039942880118, 'min_child_weight': 0.5491236914137484}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:19,687] Trial 79 finished with value: 0.769760878749472 and parameters: {'max_depth': 4, 'learning_rate': 0.06591980145318285, 'n_estimators': 800, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'reg_lambda': 2.5796738446810052, 'reg_alpha': 0.6159181210977013, 'min_child_weight': 5.788721932357297}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:20,555] Trial 80 finished with value: 0.7665967046894804 and parameters: {'max_depth': 6, 'learning_rate': 0.04383327262335877, 'n_estimators': 700, 'subsample': 0.30000000000000004, 'colsample_bytree': 1.0, 'reg_lambda': 1.154506861471814, 'reg_alpha': 1.2409104185978959, 'min_child_weight': 2.5327619928553218}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:21,285] Trial 81 finished with value: 0.7696838191803972 and parameters: {'max_depth': 4, 'learning_rate': 0.025482376649385543, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 9.723682703514447, 'reg_alpha': 2.348403800742283, 'min_child_weight': 1.4175799458921852}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:22,033] Trial 82 finished with value: 0.7701863962822137 and parameters: {'max_depth': 4, 'learning_rate': 0.03706639525195976, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7, 'reg_lambda': 7.448989121493349, 'reg_alpha': 2.1773005528991916, 'min_child_weight': 0.8818490495694213}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:23,037] Trial 83 finished with value: 0.7707389945078158 and parameters: {'max_depth': 5, 'learning_rate': 0.03182628858392808, 'n_estimators': 1000, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 4.725138606022475, 'reg_alpha': 1.3051202916139717, 'min_child_weight': 0.44386704958219453}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:23,554] Trial 84 finished with value: 0.7716677651035064 and parameters: {'max_depth': 3, 'learning_rate': 0.03897843665171121, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 6.475253081951682, 'reg_alpha': 0.7814234370043379, 'min_child_weight': 3.07710348355847}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:24,283] Trial 85 finished with value: 0.7702746092099704 and parameters: {'max_depth': 4, 'learning_rate': 0.0516156268401, 'n_estimators': 900, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_lambda': 9.741854716903331, 'reg_alpha': 1.0578952060775315, 'min_child_weight': 1.6920398935042817}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:24,850] Trial 86 finished with value: 0.7715964512040558 and parameters: {'max_depth': 3, 'learning_rate': 0.03488411132161838, 'n_estimators': 1000, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 3.142958952645638, 'reg_alpha': 0.46308367292343705, 'min_child_weight': 0.9895059894593077}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:25,517] Trial 87 finished with value: 0.770483481199831 and parameters: {'max_depth': 4, 'learning_rate': 0.020332914347115552, 'n_estimators': 800, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.8566285738285955, 'reg_alpha': 0.231606283462531, 'min_child_weight': 6.919964208295717}. Best is trial 71 with value: 0.7733455006337135.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:42:26,419] Trial 88 finished with value: 0.7686516265314745 and parameters: {'max_depth': 5, 'learning_rate': 0.045126993397019796, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.8, 'reg_lambda': 4.293249364643706, 'reg_alpha': 1.5765846205718312, 'min_child_weight': 4.334118076792393}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:26,776] Trial 89 finished with value: 0.7384402196873681 and parameters: {'max_depth': 1, 'learning_rate': 0.027669168780014387, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 7.084302481183561, 'reg_alpha': 0.1345449538570042, 'min_child_weight': 2.5510624333084553}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:27,920] Trial 90 finished with value: 0.7625017321504014 and parameters: {'max_depth': 6, 'learning_rate': 0.05471065086890164, 'n_estimators': 1000, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'reg_lambda': 2.5013483247458863, 'reg_alpha': 0.6201134236068833, 'min_child_weight': 1.5903574475785884}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:28,252] Trial 91 finished with value: 0.7700457963667089 and parameters: {'max_depth': 4, 'learning_rate': 0.03944959588966305, 'n_estimators': 400, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.39634463973242, 'reg_alpha': 0.4932759044023196, 'min_child_weight': 8.04832723631532}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:28,982] Trial 92 finished with value: 0.7702036332910858 and parameters: {'max_depth': 4, 'learning_rate': 0.03227905276184058, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 3.628850120817474, 'reg_alpha': 0.3602930874969563, 'min_child_weight': 3.8040995029864457}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:30,100] Trial 93 finished with value: 0.7702975918884664 and parameters: {'max_depth': 7, 'learning_rate': 0.036996571927310845, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 5.109871344202346, 'reg_alpha': 0.947472066294995, 'min_child_weight': 7.05595493300786}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:30,561] Trial 94 finished with value: 0.7709056189269117 and parameters: {'max_depth': 3, 'learning_rate': 0.042080047615069754, 'n_estimators': 800, 'subsample': 0.2, 'colsample_bytree': 1.0, 'reg_lambda': 7.508172702099091, 'reg_alpha': 0.4883229440736311, 'min_child_weight': 2.686854529075317}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:30,907] Trial 95 finished with value: 0.7703976341360372 and parameters: {'max_depth': 5, 'learning_rate': 0.049563876768377715, 'n_estimators': 300, 'subsample': 0.2, 'colsample_bytree': 0.7, 'reg_lambda': 1.2354829832563403, 'reg_alpha': 1.3639460543183144, 'min_child_weight': 0.6363103441550019}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:31,279] Trial 96 finished with value: 0.7658639628221378 and parameters: {'max_depth': 2, 'learning_rate': 0.045796499706906524, 'n_estimators': 800, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.8, 'reg_lambda': 2.4998907001026853, 'reg_alpha': 0.6342866852788138, 'min_child_weight': 4.576361130324946}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:31,999] Trial 97 finished with value: 0.770572708069286 and parameters: {'max_depth': 4, 'learning_rate': 0.03256500679599838, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 0.8407815253987422, 'reg_alpha': 0.2183237049539344, 'min_child_weight': 1.183185109422465}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:32,575] Trial 98 finished with value: 0.7716018588931136 and parameters: {'max_depth': 3, 'learning_rate': 0.060776333145660076, 'n_estimators': 1000, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_lambda': 4.830860130891064, 'reg_alpha': 2.6483763963955123, 'min_child_weight': 0.2298500677711052}. Best is trial 71 with value: 0.7733455006337135.\n",
      "[I 2023-07-05 17:42:33,461] Trial 99 finished with value: 0.7711425433037601 and parameters: {'max_depth': 5, 'learning_rate': 0.037587809704289266, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.7580955297046255, 'reg_alpha': 4.142873825962393, 'min_child_weight': 9.364625690499189}. Best is trial 71 with value: 0.7733455006337135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of K-fold CV for LGBMClassifier() : [0.70732379 0.7001652  0.70787445 0.70594714 0.70201047]\n",
      "Mean: 0.7046642076247487\n",
      "Std: 0.003043299599803405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 4, 'learning_rate': 0.03831628585040062, 'n_estimators': 900, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 1.6589792192011186, 'reg_alpha': 0.5750262101450965, 'min_child_weight': 5.16458108325335}\n",
      "Test Accuracy: 0.7110655737704918\n",
      "Test F1 Score: 0.6647646219686162\n",
      "Test AUC: 0.7736158850866075\n",
      "Test Precision Score: 0.7147239263803681\n"
     ]
    }
   ],
   "source": [
    "# lightgbm with odds data\n",
    "optimiser = Optimiser(df, \"LGBM\", verbosity=False)\n",
    "model = optimiser.optimise()\n",
    "model_filename = \"lgbm_home_win_with_odds.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f7bb426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:43:49,888] A new study created in memory with name: no-name-4162b388-d646-479e-b596-2d4e90ec9550\n",
      "[I 2023-07-05 17:43:53,465] Trial 0 finished with value: 0.7556758766370933 and parameters: {'max_depth': 3, 'learning_rate': 0.013115152641434652, 'n_estimators': 1000, 'subsample': 0.6000000000000001, 'colsample_bytree': 1.0, 'reg_lambda': 0.17803358180236992, 'reg_alpha': 0.00013134638906976326, 'gamma': 0.0016536198180401554, 'min_child_weight': 5}. Best is trial 0 with value: 0.7556758766370933.\n",
      "[I 2023-07-05 17:43:54,814] Trial 1 finished with value: 0.7474771440642163 and parameters: {'max_depth': 10, 'learning_rate': 0.02611725081303864, 'n_estimators': 200, 'subsample': 1.0, 'colsample_bytree': 0.2, 'reg_lambda': 0.017553666146364794, 'reg_alpha': 0.13551824116877184, 'gamma': 0.00013583791485704687, 'min_child_weight': 10}. Best is trial 0 with value: 0.7556758766370933.\n",
      "[I 2023-07-05 17:43:57,173] Trial 2 finished with value: 0.7533167722855935 and parameters: {'max_depth': 8, 'learning_rate': 0.08150115161288453, 'n_estimators': 400, 'subsample': 0.4, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.0840761946221527, 'reg_alpha': 0.004066962624536432, 'gamma': 0.5821901927207196, 'min_child_weight': 5}. Best is trial 0 with value: 0.7556758766370933.\n",
      "[I 2023-07-05 17:44:02,648] Trial 3 finished with value: 0.7575719476130123 and parameters: {'max_depth': 9, 'learning_rate': 0.014637025921460748, 'n_estimators': 900, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.2, 'reg_lambda': 1.8308515864022112, 'reg_alpha': 0.0004150445381430306, 'gamma': 5.6094740553854684e-05, 'min_child_weight': 5}. Best is trial 3 with value: 0.7575719476130123.\n",
      "[I 2023-07-05 17:44:03,230] Trial 4 finished with value: 0.7283092522179975 and parameters: {'max_depth': 1, 'learning_rate': 0.002344692014453564, 'n_estimators': 300, 'subsample': 0.2, 'colsample_bytree': 0.2, 'reg_lambda': 0.00033614037995791904, 'reg_alpha': 0.0008244533690515938, 'gamma': 1.845742116975359, 'min_child_weight': 6}. Best is trial 3 with value: 0.7575719476130123.\n",
      "[I 2023-07-05 17:44:05,427] Trial 5 finished with value: 0.7621600337980565 and parameters: {'max_depth': 2, 'learning_rate': 0.08924198208141897, 'n_estimators': 800, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_lambda': 0.19165822998585774, 'reg_alpha': 0.8743429340063337, 'gamma': 0.06890041363952099, 'min_child_weight': 9}. Best is trial 5 with value: 0.7621600337980565.\n",
      "[I 2023-07-05 17:44:09,604] Trial 6 finished with value: 0.7504016899028306 and parameters: {'max_depth': 5, 'learning_rate': 0.003142870871459106, 'n_estimators': 700, 'subsample': 0.9000000000000001, 'colsample_bytree': 1.0, 'reg_lambda': 0.0001360004637524707, 'reg_alpha': 1.7836534779133394e-05, 'gamma': 0.1142267185229441, 'min_child_weight': 8}. Best is trial 5 with value: 0.7621600337980565.\n",
      "[I 2023-07-05 17:44:13,782] Trial 7 finished with value: 0.7679411913814955 and parameters: {'max_depth': 7, 'learning_rate': 0.015235993957356975, 'n_estimators': 600, 'subsample': 0.7, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 0.0007849633339520184, 'reg_alpha': 0.002972581575190162, 'gamma': 0.0016657146887474933, 'min_child_weight': 6}. Best is trial 7 with value: 0.7679411913814955.\n",
      "[I 2023-07-05 17:44:14,124] Trial 8 finished with value: 0.7460441064638783 and parameters: {'max_depth': 4, 'learning_rate': 0.041807656197632624, 'n_estimators': 100, 'subsample': 0.2, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.010095954004477017, 'reg_alpha': 3.6394115452369915, 'gamma': 0.00017007887849613228, 'min_child_weight': 4}. Best is trial 7 with value: 0.7679411913814955.\n",
      "[I 2023-07-05 17:44:17,163] Trial 9 finished with value: 0.7526678495986481 and parameters: {'max_depth': 10, 'learning_rate': 0.007902863056562006, 'n_estimators': 500, 'subsample': 0.4, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.13249526142005943, 'reg_alpha': 4.769620233535888, 'gamma': 0.3082904000373976, 'min_child_weight': 6}. Best is trial 7 with value: 0.7679411913814955.\n",
      "[I 2023-07-05 17:44:21,250] Trial 10 finished with value: 0.7476312632023658 and parameters: {'max_depth': 6, 'learning_rate': 0.001363851546332319, 'n_estimators': 600, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_lambda': 1.0981822628841093e-05, 'reg_alpha': 0.03007521304078888, 'gamma': 0.004568443763079925, 'min_child_weight': 1}. Best is trial 7 with value: 0.7679411913814955.\n",
      "[I 2023-07-05 17:44:26,444] Trial 11 finished with value: 0.7493427967891847 and parameters: {'max_depth': 7, 'learning_rate': 0.09951185433123083, 'n_estimators': 800, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_lambda': 2.652113014767906, 'reg_alpha': 0.1783772014665635, 'gamma': 0.01894553006083508, 'min_child_weight': 10}. Best is trial 7 with value: 0.7679411913814955.\n",
      "[I 2023-07-05 17:44:27,966] Trial 12 finished with value: 0.7395579214195185 and parameters: {'max_depth': 1, 'learning_rate': 0.03795664920108703, 'n_estimators': 700, 'subsample': 0.4, 'colsample_bytree': 0.8, 'reg_lambda': 0.0014780254816851655, 'reg_alpha': 0.008060634766763703, 'gamma': 0.025715789647583462, 'min_child_weight': 8}. Best is trial 7 with value: 0.7679411913814955.\n",
      "[I 2023-07-05 17:44:30,031] Trial 13 finished with value: 0.7482227291930714 and parameters: {'max_depth': 3, 'learning_rate': 0.00871427994770153, 'n_estimators': 600, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_lambda': 0.0010324384990583718, 'reg_alpha': 0.5279729431384655, 'gamma': 0.0014727722494899094, 'min_child_weight': 8}. Best is trial 7 with value: 0.7679411913814955.\n",
      "[I 2023-07-05 17:44:34,648] Trial 14 finished with value: 0.7649730460498522 and parameters: {'max_depth': 6, 'learning_rate': 0.04587583901018972, 'n_estimators': 800, 'subsample': 0.7, 'colsample_bytree': 0.4, 'reg_lambda': 8.892636255261417, 'reg_alpha': 0.035332789765738136, 'gamma': 8.474153817229087, 'min_child_weight': 2}. Best is trial 7 with value: 0.7679411913814955.\n",
      "[I 2023-07-05 17:44:40,597] Trial 15 finished with value: 0.767882044782425 and parameters: {'max_depth': 6, 'learning_rate': 0.021702462355538684, 'n_estimators': 1000, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_lambda': 3.0272474303085186, 'reg_alpha': 0.03346740796918378, 'gamma': 6.887928577600959, 'min_child_weight': 2}. Best is trial 7 with value: 0.7679411913814955.\n",
      "[I 2023-07-05 17:44:48,030] Trial 16 finished with value: 0.7696256865230249 and parameters: {'max_depth': 8, 'learning_rate': 0.020644946906637568, 'n_estimators': 1000, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_lambda': 0.004352456888858731, 'reg_alpha': 0.004108815582887404, 'gamma': 5.04922068078334, 'min_child_weight': 3}. Best is trial 16 with value: 0.7696256865230249.\n",
      "[I 2023-07-05 17:44:51,555] Trial 17 finished with value: 0.7562234051542037 and parameters: {'max_depth': 8, 'learning_rate': 0.005607115161933954, 'n_estimators': 400, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.003366487280902765, 'reg_alpha': 0.0020361034637882583, 'gamma': 1.82304920815548e-05, 'min_child_weight': 3}. Best is trial 16 with value: 0.7696256865230249.\n",
      "[I 2023-07-05 17:44:58,514] Trial 18 finished with value: 0.7670610899873258 and parameters: {'max_depth': 8, 'learning_rate': 0.01863821266236695, 'n_estimators': 900, 'subsample': 0.8, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 0.00015121825854301065, 'reg_alpha': 0.0030936879604830402, 'gamma': 1.2681428599194229, 'min_child_weight': 7}. Best is trial 16 with value: 0.7696256865230249.\n",
      "[I 2023-07-05 17:45:02,227] Trial 19 finished with value: 0.7621455006337137 and parameters: {'max_depth': 7, 'learning_rate': 0.012112344161918573, 'n_estimators': 500, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 0.004414851050779681, 'reg_alpha': 0.00018321611812556653, 'gamma': 0.005836764077655255, 'min_child_weight': 3}. Best is trial 16 with value: 0.7696256865230249.\n",
      "[I 2023-07-05 17:45:08,305] Trial 20 finished with value: 0.7642430080270385 and parameters: {'max_depth': 9, 'learning_rate': 0.006805445251897295, 'n_estimators': 700, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_lambda': 0.03299332758981143, 'reg_alpha': 0.0016171812053376914, 'gamma': 0.08521401247068278, 'min_child_weight': 4}. Best is trial 16 with value: 0.7696256865230249.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:45:13,494] Trial 21 finished with value: 0.763410223912125 and parameters: {'max_depth': 5, 'learning_rate': 0.02076391283854109, 'n_estimators': 1000, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_lambda': 0.5431015404376119, 'reg_alpha': 0.013196856199393281, 'gamma': 9.274531534298323, 'min_child_weight': 1}. Best is trial 16 with value: 0.7696256865230249.\n",
      "[I 2023-07-05 17:45:20,607] Trial 22 finished with value: 0.7687678918462189 and parameters: {'max_depth': 7, 'learning_rate': 0.028972586639300506, 'n_estimators': 1000, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.5, 'reg_lambda': 0.026836060891380305, 'reg_alpha': 0.014817261148075436, 'gamma': 3.6594270517713685, 'min_child_weight': 2}. Best is trial 16 with value: 0.7696256865230249.\n",
      "[I 2023-07-05 17:45:27,159] Trial 23 finished with value: 0.7692268694550064 and parameters: {'max_depth': 7, 'learning_rate': 0.024694389511390292, 'n_estimators': 900, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.5, 'reg_lambda': 0.032303930767339735, 'reg_alpha': 0.011275063655658491, 'gamma': 2.907737790329432, 'min_child_weight': 3}. Best is trial 16 with value: 0.7696256865230249.\n",
      "[I 2023-07-05 17:45:34,994] Trial 24 finished with value: 0.7640280523869878 and parameters: {'max_depth': 9, 'learning_rate': 0.032437577798414115, 'n_estimators': 900, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.5, 'reg_lambda': 0.03275439147053579, 'reg_alpha': 0.010933498320565118, 'gamma': 2.4953671620560725, 'min_child_weight': 3}. Best is trial 16 with value: 0.7696256865230249.\n",
      "[I 2023-07-05 17:45:41,256] Trial 25 finished with value: 0.7696750316856782 and parameters: {'max_depth': 7, 'learning_rate': 0.028296297982049894, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.007267201992673047, 'reg_alpha': 0.08253777909858116, 'gamma': 0.3714314000914313, 'min_child_weight': 2}. Best is trial 25 with value: 0.7696750316856782.\n",
      "[I 2023-07-05 17:45:47,419] Trial 26 finished with value: 0.7627964512040557 and parameters: {'max_depth': 8, 'learning_rate': 0.05816664844643963, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.007300311106886687, 'reg_alpha': 0.07703540112353172, 'gamma': 1.0602416155750234, 'min_child_weight': 4}. Best is trial 25 with value: 0.7696750316856782.\n",
      "[I 2023-07-05 17:45:52,112] Trial 27 finished with value: 0.76717127165188 and parameters: {'max_depth': 5, 'learning_rate': 0.026386073127761023, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.004265471938626718, 'reg_alpha': 0.006716551471281497, 'gamma': 0.3933092787807323, 'min_child_weight': 1}. Best is trial 25 with value: 0.7696750316856782.\n",
      "[I 2023-07-05 17:45:57,612] Trial 28 finished with value: 0.7611447401774398 and parameters: {'max_depth': 7, 'learning_rate': 0.010847685749626407, 'n_estimators': 800, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.015010127604323062, 'reg_alpha': 0.0889398258265769, 'gamma': 3.4690141166044555, 'min_child_weight': 3}. Best is trial 25 with value: 0.7696750316856782.\n",
      "[I 2023-07-05 17:46:01,661] Trial 29 finished with value: 0.7714697084917617 and parameters: {'max_depth': 4, 'learning_rate': 0.05292825014956882, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.07858167391426564, 'reg_alpha': 0.0007201790289214779, 'gamma': 0.9079604830575124, 'min_child_weight': 2}. Best is trial 29 with value: 0.7714697084917617.\n",
      "[I 2023-07-05 17:46:05,498] Trial 30 finished with value: 0.7707964512040558 and parameters: {'max_depth': 4, 'learning_rate': 0.05842228336848068, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.07826843217204117, 'reg_alpha': 0.0008866119271751724, 'gamma': 0.7179975239866724, 'min_child_weight': 2}. Best is trial 29 with value: 0.7714697084917617.\n",
      "[I 2023-07-05 17:46:09,325] Trial 31 finished with value: 0.7718354034643009 and parameters: {'max_depth': 4, 'learning_rate': 0.058566944579751354, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.08613563523004622, 'reg_alpha': 0.0008851000815932566, 'gamma': 0.7686233166271699, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:12,526] Trial 32 finished with value: 0.7546207013096747 and parameters: {'max_depth': 4, 'learning_rate': 0.057226951580707806, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.2, 'reg_lambda': 0.08383075534094284, 'reg_alpha': 0.0007253356513309208, 'gamma': 0.3049778388853797, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:15,298] Trial 33 finished with value: 0.7676180819602872 and parameters: {'max_depth': 3, 'learning_rate': 0.0663030772794773, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.22506204596480733, 'reg_alpha': 0.000196684437003473, 'gamma': 0.7069730809511767, 'min_child_weight': 1}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:19,124] Trial 34 finished with value: 0.7706531474440219 and parameters: {'max_depth': 4, 'learning_rate': 0.07195068709522463, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.47925198509128664, 'reg_alpha': 7.618963606539649e-05, 'gamma': 0.18396684051013573, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:22,030] Trial 35 finished with value: 0.7615705956907478 and parameters: {'max_depth': 4, 'learning_rate': 0.07501651715730379, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.2, 'reg_lambda': 0.5564938837590433, 'reg_alpha': 7.127855022199399e-05, 'gamma': 1.2274927536578597, 'min_child_weight': 4}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:24,231] Trial 36 finished with value: 0.7506599070553444 and parameters: {'max_depth': 2, 'learning_rate': 0.05612724594171214, 'n_estimators': 800, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.2, 'reg_lambda': 0.0731853500213399, 'reg_alpha': 0.00032413858313515607, 'gamma': 0.6430115310790906, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:27,140] Trial 37 finished with value: 0.7568696239966203 and parameters: {'max_depth': 4, 'learning_rate': 0.08016528715916081, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.2, 'reg_lambda': 0.36143553001326517, 'reg_alpha': 6.955686259609394e-05, 'gamma': 0.19905513636216987, 'min_child_weight': 1}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:30,191] Trial 38 finished with value: 0.7610555133079847 and parameters: {'max_depth': 2, 'learning_rate': 0.047700820695144926, 'n_estimators': 1000, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 0.08116495092935896, 'reg_alpha': 0.00076028141154431, 'gamma': 0.16272584527892342, 'min_child_weight': 5}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:32,928] Trial 39 finished with value: 0.7706815378115759 and parameters: {'max_depth': 3, 'learning_rate': 0.09463134882248597, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 1.0671331773395005, 'reg_alpha': 0.0011942615014058078, 'gamma': 1.5598135248127714, 'min_child_weight': 4}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:33,518] Trial 40 finished with value: 0.7502746092099704 and parameters: {'max_depth': 3, 'learning_rate': 0.09374633301707308, 'n_estimators': 200, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.2, 'reg_lambda': 0.8520318110955133, 'reg_alpha': 0.0014037954215684102, 'gamma': 1.8557058164219422, 'min_child_weight': 5}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:37,409] Trial 41 finished with value: 0.7706612589776088 and parameters: {'max_depth': 4, 'learning_rate': 0.075323504719404, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.26472967097947303, 'reg_alpha': 0.0004459687770591136, 'gamma': 0.6819024666289312, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:46:40,170] Trial 42 finished with value: 0.770552429235319 and parameters: {'max_depth': 3, 'learning_rate': 0.0985005781834045, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.16546677461501663, 'reg_alpha': 0.0006831624619559347, 'gamma': 0.7580954487919044, 'min_child_weight': 4}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:42,632] Trial 43 finished with value: 0.7573133924799325 and parameters: {'max_depth': 2, 'learning_rate': 0.03560304073641522, 'n_estimators': 800, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 1.1503736513745904, 'reg_alpha': 0.00041493469211161346, 'gamma': 1.598864281132709, 'min_child_weight': 1}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:47,246] Trial 44 finished with value: 0.7607763413603718 and parameters: {'max_depth': 5, 'learning_rate': 0.047948310931628976, 'n_estimators': 1000, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.2105383297121049, 'reg_alpha': 0.0014020625156664888, 'gamma': 0.5580370506554365, 'min_child_weight': 3}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:50,166] Trial 45 finished with value: 0.7553848753696664 and parameters: {'max_depth': 4, 'learning_rate': 0.0685798615033911, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.2, 'reg_lambda': 0.0597001530784989, 'reg_alpha': 0.0003036907307080805, 'gamma': 0.04936214527406625, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:53,446] Trial 46 finished with value: 0.7687212505280947 and parameters: {'max_depth': 4, 'learning_rate': 0.03933314832477462, 'n_estimators': 700, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.28563694104359877, 'reg_alpha': 0.0010073864137090493, 'gamma': 1.6273739575688988, 'min_child_weight': 4}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:46:56,500] Trial 47 finished with value: 0.7566448669201521 and parameters: {'max_depth': 3, 'learning_rate': 0.08258680661588855, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.1466231204544196, 'reg_alpha': 0.0027575900112857313, 'gamma': 4.833485579830007, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:00,588] Trial 48 finished with value: 0.763406844106464 and parameters: {'max_depth': 5, 'learning_rate': 0.05666113574429748, 'n_estimators': 900, 'subsample': 0.5, 'colsample_bytree': 0.4, 'reg_lambda': 0.11738262384352391, 'reg_alpha': 0.0006581964095641033, 'gamma': 0.11672204682197726, 'min_child_weight': 1}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:03,015] Trial 49 finished with value: 0.7602913392479933 and parameters: {'max_depth': 2, 'learning_rate': 0.04492075726450518, 'n_estimators': 800, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_lambda': 0.05230282039966997, 'reg_alpha': 0.005013127355303006, 'gamma': 0.8666622119073893, 'min_child_weight': 5}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:06,329] Trial 50 finished with value: 0.7622739332488382 and parameters: {'max_depth': 3, 'learning_rate': 0.08155755599290833, 'n_estimators': 1000, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.2, 'reg_lambda': 1.5010428153532547, 'reg_alpha': 0.0030128497748086124, 'gamma': 2.187700900484781, 'min_child_weight': 3}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:10,204] Trial 51 finished with value: 0.7705233629066328 and parameters: {'max_depth': 4, 'learning_rate': 0.06868068586002533, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.41594767660338866, 'reg_alpha': 0.00013098233435290127, 'gamma': 0.27788017411473376, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:14,062] Trial 52 finished with value: 0.7652637093367132 and parameters: {'max_depth': 4, 'learning_rate': 0.09723839727977776, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.28255912620357654, 'reg_alpha': 0.0005069413540362405, 'gamma': 0.18111330356258606, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:18,923] Trial 53 finished with value: 0.7646066751161807 and parameters: {'max_depth': 5, 'learning_rate': 0.06893113186605213, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.6449812399786443, 'reg_alpha': 0.0013475503532743294, 'gamma': 0.481960566199393, 'min_child_weight': 1}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:22,867] Trial 54 finished with value: 0.7689618926911702 and parameters: {'max_depth': 4, 'learning_rate': 0.03921270152497894, 'n_estimators': 900, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.945826051382383, 'reg_alpha': 2.0800168984689147e-05, 'gamma': 1.0285373131007414, 'min_child_weight': 7}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:26,080] Trial 55 finished with value: 0.7689777777777778 and parameters: {'max_depth': 3, 'learning_rate': 0.05240310059708928, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.132575255864277, 'reg_alpha': 0.00043141236036017177, 'gamma': 0.5148008981939828, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:28,127] Trial 56 finished with value: 0.7619467680608365 and parameters: {'max_depth': 6, 'learning_rate': 0.06309964240479148, 'n_estimators': 400, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.2, 'reg_lambda': 2.5171247354723754, 'reg_alpha': 0.0009382671465536822, 'gamma': 0.24089108950991214, 'min_child_weight': 3}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:30,191] Trial 57 finished with value: 0.7395038445289396 and parameters: {'max_depth': 1, 'learning_rate': 0.07875261977453826, 'n_estimators': 900, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_lambda': 0.34772722747783946, 'reg_alpha': 0.002176914961810324, 'gamma': 5.983424619325624, 'min_child_weight': 3}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:31,650] Trial 58 finished with value: 0.7660441064638783 and parameters: {'max_depth': 5, 'learning_rate': 0.044739215129029765, 'n_estimators': 300, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.05066992165625034, 'reg_alpha': 0.000314788855712737, 'gamma': 0.09624725745234039, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:35,391] Trial 59 finished with value: 0.7683562315166877 and parameters: {'max_depth': 4, 'learning_rate': 0.03327469138340899, 'n_estimators': 800, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.11936107825899477, 'reg_alpha': 0.00020671133429266462, 'gamma': 3.085033723902946, 'min_child_weight': 1}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:38,996] Trial 60 finished with value: 0.7685144064216308 and parameters: {'max_depth': 3, 'learning_rate': 0.051487889843034165, 'n_estimators': 1000, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_lambda': 0.018694416362670444, 'reg_alpha': 0.001942660457399372, 'gamma': 1.531219906335011, 'min_child_weight': 3}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:41,091] Trial 61 finished with value: 0.7667450781580061 and parameters: {'max_depth': 2, 'learning_rate': 0.09965690696214369, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.20551152747118814, 'reg_alpha': 0.0009165666069815232, 'gamma': 0.9166325735656917, 'min_child_weight': 4}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:43,844] Trial 62 finished with value: 0.771648838191804 and parameters: {'max_depth': 3, 'learning_rate': 0.08970590621671426, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.5130843566214295, 'reg_alpha': 0.0006102970186663195, 'gamma': 0.7376789312687321, 'min_child_weight': 6}. Best is trial 31 with value: 0.7718354034643009.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:47:47,645] Trial 63 finished with value: 0.7690196873679764 and parameters: {'max_depth': 4, 'learning_rate': 0.07935541775705542, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.8051877485804004, 'reg_alpha': 0.00525626413065774, 'gamma': 0.46291239890188707, 'min_child_weight': 7}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:51,955] Trial 64 finished with value: 0.7691180397127165 and parameters: {'max_depth': 5, 'learning_rate': 0.06114779309909109, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.4315395995409495, 'reg_alpha': 0.00048001514498976735, 'gamma': 1.1137364541813608, 'min_child_weight': 6}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:55,653] Trial 65 finished with value: 0.769061934938741 and parameters: {'max_depth': 3, 'learning_rate': 0.08571035491527962, 'n_estimators': 1000, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 1.7138519254178997, 'reg_alpha': 0.0012226856779514082, 'gamma': 0.3687889920009697, 'min_child_weight': 5}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:47:57,536] Trial 66 finished with value: 0.7529436417405999 and parameters: {'max_depth': 3, 'learning_rate': 0.07022081166323937, 'n_estimators': 700, 'subsample': 1.0, 'colsample_bytree': 0.2, 'reg_lambda': 0.5631519461409922, 'reg_alpha': 0.0020847008845172187, 'gamma': 2.411222978599187, 'min_child_weight': 6}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:48:00,407] Trial 67 finished with value: 0.7684272074355725 and parameters: {'max_depth': 4, 'learning_rate': 0.05874801352200147, 'n_estimators': 600, 'subsample': 0.9000000000000001, 'colsample_bytree': 1.0, 'reg_lambda': 0.23569847384422732, 'reg_alpha': 0.003871396881383757, 'gamma': 4.3928511932990695, 'min_child_weight': 7}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:48:04,669] Trial 68 finished with value: 0.7675650190114068 and parameters: {'max_depth': 6, 'learning_rate': 0.08919818321841069, 'n_estimators': 800, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 1.2131942531632056, 'reg_alpha': 0.0006239323266157854, 'gamma': 0.2821296663431873, 'min_child_weight': 6}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:48:07,357] Trial 69 finished with value: 0.75639171947613 and parameters: {'max_depth': 2, 'learning_rate': 0.04132844802527087, 'n_estimators': 900, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_lambda': 5.403219462590775, 'reg_alpha': 0.0001494558487285555, 'gamma': 0.7940596430233633, 'min_child_weight': 2}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:48:11,186] Trial 70 finished with value: 0.7572802703844529 and parameters: {'max_depth': 5, 'learning_rate': 0.04977240839483342, 'n_estimators': 1000, 'subsample': 1.0, 'colsample_bytree': 0.2, 'reg_lambda': 0.6965331761593271, 'reg_alpha': 0.00010218314342585043, 'gamma': 0.15575569939142467, 'min_child_weight': 1}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:48:13,964] Trial 71 finished with value: 0.7697994085340094 and parameters: {'max_depth': 3, 'learning_rate': 0.09689450261618064, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.16390772750711047, 'reg_alpha': 0.0006320637008133964, 'gamma': 0.6907146699250137, 'min_child_weight': 4}. Best is trial 31 with value: 0.7718354034643009.\n",
      "[I 2023-07-05 17:48:16,725] Trial 72 finished with value: 0.7731109421208281 and parameters: {'max_depth': 3, 'learning_rate': 0.07452314631965326, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.09919734255846553, 'reg_alpha': 0.0002524212417811137, 'gamma': 1.371890617189692, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:19,649] Trial 73 finished with value: 0.7563325728770596 and parameters: {'max_depth': 4, 'learning_rate': 0.07221630516996598, 'n_estimators': 1000, 'subsample': 0.2, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.1030355497131697, 'reg_alpha': 0.0002572668437914958, 'gamma': 1.6145773825280918, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:21,660] Trial 74 finished with value: 0.7715271651880018 and parameters: {'max_depth': 4, 'learning_rate': 0.06321168844959112, 'n_estimators': 500, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.08784448026536198, 'reg_alpha': 0.0002732853589575435, 'gamma': 3.028105570128757, 'min_child_weight': 8}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:23,634] Trial 75 finished with value: 0.7616513730460499 and parameters: {'max_depth': 3, 'learning_rate': 0.062489390820803944, 'n_estimators': 500, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.5, 'reg_lambda': 0.04764444230064704, 'reg_alpha': 0.0003932139781482844, 'gamma': 7.070605308818082, 'min_child_weight': 8}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:25,094] Trial 76 finished with value: 0.7560953105196451 and parameters: {'max_depth': 3, 'learning_rate': 0.0853887011641361, 'n_estimators': 500, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.4, 'reg_lambda': 0.0857429022278104, 'reg_alpha': 0.00021611812933390788, 'gamma': 3.0857709263982143, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:27,536] Trial 77 finished with value: 0.7718678495986481 and parameters: {'max_depth': 4, 'learning_rate': 0.05219754116802026, 'n_estimators': 600, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.025183238627690778, 'reg_alpha': 0.000985587819992441, 'gamma': 2.431528445076676, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:28,557] Trial 78 finished with value: 0.7451792141951838 and parameters: {'max_depth': 2, 'learning_rate': 0.055711670363143735, 'n_estimators': 400, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.024473409883551806, 'reg_alpha': 0.0010183247678220975, 'gamma': 4.672883160282707, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:30,983] Trial 79 finished with value: 0.7713115335868188 and parameters: {'max_depth': 4, 'learning_rate': 0.05109482786675123, 'n_estimators': 600, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.034071105617519526, 'reg_alpha': 0.001351395404322354, 'gamma': 2.6805005736990735, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:34,207] Trial 80 finished with value: 0.7656043937473596 and parameters: {'max_depth': 5, 'learning_rate': 0.035608566007225284, 'n_estimators': 600, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 0.0311281912084714, 'reg_alpha': 0.001714332599527297, 'gamma': 8.957255770401499, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:36,653] Trial 81 finished with value: 0.7637904520490071 and parameters: {'max_depth': 4, 'learning_rate': 0.0517855709210523, 'n_estimators': 600, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 0.04453640512589593, 'reg_alpha': 0.0010419803148043712, 'gamma': 2.326558563746638, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:38,711] Trial 82 finished with value: 0.7693519222644698 and parameters: {'max_depth': 4, 'learning_rate': 0.04248731615422703, 'n_estimators': 500, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.06968570947916096, 'reg_alpha': 0.0008116733006463418, 'gamma': 1.3121018552795474, 'min_child_weight': 8}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:40,975] Trial 83 finished with value: 0.7681088297422898 and parameters: {'max_depth': 3, 'learning_rate': 0.06344461042352569, 'n_estimators': 700, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.012938124017008291, 'reg_alpha': 0.0003049377211892836, 'gamma': 2.041978016077994, 'min_child_weight': 8}. Best is trial 72 with value: 0.7731109421208281.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:48:42,621] Trial 84 finished with value: 0.7597897760878749 and parameters: {'max_depth': 3, 'learning_rate': 0.04670322545655829, 'n_estimators': 500, 'subsample': 1.0, 'colsample_bytree': 0.4, 'reg_lambda': 0.019474053761100146, 'reg_alpha': 0.0005842725247262394, 'gamma': 3.6095367720218383, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:45,094] Trial 85 finished with value: 0.7712696239966204 and parameters: {'max_depth': 4, 'learning_rate': 0.07429245538940114, 'n_estimators': 600, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.03544755753933173, 'reg_alpha': 0.0019216149884007034, 'gamma': 1.242631650492688, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:47,517] Trial 86 finished with value: 0.7628366708914238 and parameters: {'max_depth': 4, 'learning_rate': 0.05392456448182267, 'n_estimators': 600, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.04213286279593391, 'reg_alpha': 0.0024385332399913073, 'gamma': 6.199732179606563, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:50,238] Trial 87 finished with value: 0.7725830164765526 and parameters: {'max_depth': 5, 'learning_rate': 0.06661185657712972, 'n_estimators': 500, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.5, 'reg_lambda': 0.02558210920654448, 'reg_alpha': 0.0035337235577291713, 'gamma': 1.2538712292119223, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:52,945] Trial 88 finished with value: 0.7701732150401351 and parameters: {'max_depth': 5, 'learning_rate': 0.07619828159062404, 'n_estimators': 500, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.5, 'reg_lambda': 0.02316305408117119, 'reg_alpha': 0.0015486892438214739, 'gamma': 2.6637700629842924, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:55,141] Trial 89 finished with value: 0.7718543303760034 and parameters: {'max_depth': 5, 'learning_rate': 0.0652636428214917, 'n_estimators': 400, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.012619393148847923, 'reg_alpha': 0.0037338591536294754, 'gamma': 1.3217958626023067, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:57,368] Trial 90 finished with value: 0.7693329953527672 and parameters: {'max_depth': 5, 'learning_rate': 0.06337483091556954, 'n_estimators': 400, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.7, 'reg_lambda': 0.0134000870339291, 'reg_alpha': 0.003514454874808293, 'gamma': 4.135679754256086, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:48:59,169] Trial 91 finished with value: 0.7711438952260246 and parameters: {'max_depth': 6, 'learning_rate': 0.06657047058682702, 'n_estimators': 300, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_lambda': 0.009626438956517196, 'reg_alpha': 0.002675120307863978, 'gamma': 1.4014135857990206, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:49:01,366] Trial 92 finished with value: 0.7703266582171526 and parameters: {'max_depth': 5, 'learning_rate': 0.08725031965809894, 'n_estimators': 400, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.02762372985544305, 'reg_alpha': 0.008803261945575448, 'gamma': 1.08203288305979, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:49:03,823] Trial 93 finished with value: 0.7728466413181241 and parameters: {'max_depth': 4, 'learning_rate': 0.07504745622667446, 'n_estimators': 600, 'subsample': 1.0, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.03551973112828396, 'reg_alpha': 0.006461667772733112, 'gamma': 2.0036988521999066, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:49:06,361] Trial 94 finished with value: 0.768152429235319 and parameters: {'max_depth': 5, 'learning_rate': 0.045879355144488765, 'n_estimators': 500, 'subsample': 0.7, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.06480577769605013, 'reg_alpha': 0.004276277637490286, 'gamma': 2.237515502581907, 'min_child_weight': 8}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:49:09,231] Trial 95 finished with value: 0.7716119983100971 and parameters: {'max_depth': 4, 'learning_rate': 0.05305216911305064, 'n_estimators': 600, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.7, 'reg_lambda': 0.09874435488726346, 'reg_alpha': 0.017389632319282085, 'gamma': 3.628123194673853, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:49:13,440] Trial 96 finished with value: 0.7656348119983102 and parameters: {'max_depth': 6, 'learning_rate': 0.058143560648758294, 'n_estimators': 700, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_lambda': 0.09069697070145695, 'reg_alpha': 0.0063996393924960916, 'gamma': 1.7759156912710352, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:49:15,373] Trial 97 finished with value: 0.7683035065483735 and parameters: {'max_depth': 4, 'learning_rate': 0.041388242538001295, 'n_estimators': 400, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.7, 'reg_lambda': 0.060401860693154306, 'reg_alpha': 0.01656596784150858, 'gamma': 3.5272388379723694, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:49:16,547] Trial 98 finished with value: 0.7684677651035066 and parameters: {'max_depth': 5, 'learning_rate': 0.0666192341253776, 'n_estimators': 200, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.1301209481389146, 'reg_alpha': 0.007842935808318343, 'gamma': 0.5401005142453403, 'min_child_weight': 10}. Best is trial 72 with value: 0.7731109421208281.\n",
      "[I 2023-07-05 17:49:17,940] Trial 99 finished with value: 0.7681696662441908 and parameters: {'max_depth': 4, 'learning_rate': 0.08773633689822069, 'n_estimators': 300, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_lambda': 0.020037159804510807, 'reg_alpha': 0.005244432133243447, 'gamma': 5.798061443032992, 'min_child_weight': 9}. Best is trial 72 with value: 0.7731109421208281.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of K-fold CV for XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...) : [0.69961454 0.6847467  0.69575991 0.68309471 0.70035803]\n",
      "Mean: 0.6927147774244544\n",
      "Std: 0.007366610631281702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 3, 'learning_rate': 0.07452314631965326, 'n_estimators': 900, 'subsample': 1.0, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.09919734255846553, 'reg_alpha': 0.0002524212417811137, 'gamma': 1.371890617189692, 'min_child_weight': 9}\n",
      "Test Accuracy: 0.7040983606557377\n",
      "Test F1 Score: 0.6558627264061009\n",
      "Test AUC: 0.7709735530207014\n",
      "Test Precision Score: 0.7070914696813977\n"
     ]
    }
   ],
   "source": [
    "# xgb without odds data\n",
    "optimiser = Optimiser(df, \"XGB\", verbosity=False)\n",
    "model = optimiser.optimise()\n",
    "\n",
    "model_filename = \"xgb_home_win_with_odds.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d477b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:51:33,725] A new study created in memory with name: no-name-957ff15d-5578-469a-aab2-9b887144e92a\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:51:40,179] Trial 0 finished with value: 0.7368098014364175 and parameters: {'learning_rate': 0.059775910369254254, 'n_estimators': 900, 'subsample': 0.2, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7368098014364175.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:51:41,639] Trial 1 finished with value: 0.7259863117870722 and parameters: {'learning_rate': 0.001722312961233823, 'n_estimators': 300, 'subsample': 0.5, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7368098014364175.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:51:45,024] Trial 2 finished with value: 0.7364150401351922 and parameters: {'learning_rate': 0.0018247440531201052, 'n_estimators': 300, 'subsample': 0.7, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7368098014364175.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:52:09,500] Trial 3 finished with value: 0.7340822982678497 and parameters: {'learning_rate': 0.09215641517980822, 'n_estimators': 1000, 'subsample': 0.9000000000000001, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7368098014364175.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:52:25,077] Trial 4 finished with value: 0.7438026193493874 and parameters: {'learning_rate': 0.001163319499591668, 'n_estimators': 600, 'subsample': 0.6000000000000001, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_depth': 8, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.7438026193493874.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:52:29,624] Trial 5 finished with value: 0.7499484579636672 and parameters: {'learning_rate': 0.015583184955787678, 'n_estimators': 500, 'subsample': 0.2, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 5 with value: 0.7499484579636672.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:52:38,437] Trial 6 finished with value: 0.7506406421630757 and parameters: {'learning_rate': 0.04272045509139941, 'n_estimators': 900, 'subsample': 0.6000000000000001, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:52:42,287] Trial 7 finished with value: 0.7419964512040558 and parameters: {'learning_rate': 0.0012764746720036492, 'n_estimators': 300, 'subsample': 0.2, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:52:49,699] Trial 8 finished with value: 0.7493475285171103 and parameters: {'learning_rate': 0.011680186256299544, 'n_estimators': 400, 'subsample': 0.4, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_depth': 8, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:53:02,183] Trial 9 finished with value: 0.7418136037177863 and parameters: {'learning_rate': 0.0011958627212625733, 'n_estimators': 400, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:53:43,759] Trial 10 finished with value: 0.7458190114068441 and parameters: {'learning_rate': 0.03400698893151035, 'n_estimators': 800, 'subsample': 0.8, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:53:50,785] Trial 11 finished with value: 0.7479070553443177 and parameters: {'learning_rate': 0.02289243795273835, 'n_estimators': 700, 'subsample': 0.4, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:53:51,468] Trial 12 finished with value: 0.7351776932826363 and parameters: {'learning_rate': 0.013468889984623518, 'n_estimators': 100, 'subsample': 0.6000000000000001, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_depth': 1, 'max_features': 'log2'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:53:58,976] Trial 13 finished with value: 0.7439155048584706 and parameters: {'learning_rate': 0.004538544379585393, 'n_estimators': 600, 'subsample': 0.4, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:54:05,446] Trial 14 finished with value: 0.7504797634136037 and parameters: {'learning_rate': 0.027986637683448716, 'n_estimators': 800, 'subsample': 0.30000000000000004, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:54:16,263] Trial 15 finished with value: 0.7504621884241656 and parameters: {'learning_rate': 0.03706742513603658, 'n_estimators': 1000, 'subsample': 0.7, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 6 with value: 0.7506406421630757.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:54:22,751] Trial 16 finished with value: 0.7508211237853823 and parameters: {'learning_rate': 0.0350791906695544, 'n_estimators': 800, 'subsample': 0.30000000000000004, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 16 with value: 0.7508211237853823.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:54:30,669] Trial 17 finished with value: 0.7503476130122517 and parameters: {'learning_rate': 0.05573282516689229, 'n_estimators': 900, 'subsample': 0.5, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 16 with value: 0.7508211237853823.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:54:46,050] Trial 18 finished with value: 0.7475291930713983 and parameters: {'learning_rate': 0.0069540286017070576, 'n_estimators': 800, 'subsample': 0.7, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 16 with value: 0.7508211237853823.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:54:52,206] Trial 19 finished with value: 0.7539156738487537 and parameters: {'learning_rate': 0.08321084451488761, 'n_estimators': 700, 'subsample': 0.5, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 19 with value: 0.7539156738487537.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:54:59,194] Trial 20 finished with value: 0.7505642585551331 and parameters: {'learning_rate': 0.06771990988263955, 'n_estimators': 700, 'subsample': 0.30000000000000004, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 19 with value: 0.7539156738487537.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:55:05,336] Trial 21 finished with value: 0.75098673426278 and parameters: {'learning_rate': 0.09662277168600067, 'n_estimators': 700, 'subsample': 0.5, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 19 with value: 0.7539156738487537.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:55:09,397] Trial 22 finished with value: 0.7404880439374735 and parameters: {'learning_rate': 0.08831902026540615, 'n_estimators': 700, 'subsample': 0.5, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_depth': 1, 'max_features': 'log2'}. Best is trial 19 with value: 0.7539156738487537.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:55:13,174] Trial 23 finished with value: 0.75065855513308 and parameters: {'learning_rate': 0.0823103864992751, 'n_estimators': 600, 'subsample': 0.30000000000000004, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 19 with value: 0.7539156738487537.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:55:21,450] Trial 24 finished with value: 0.7544888888888888 and parameters: {'learning_rate': 0.09804339779182868, 'n_estimators': 700, 'subsample': 0.5, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 24 with value: 0.7544888888888888.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:55:24,402] Trial 25 finished with value: 0.7399395014786649 and parameters: {'learning_rate': 0.096204713431693, 'n_estimators': 500, 'subsample': 0.5, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_depth': 1, 'max_features': 'log2'}. Best is trial 24 with value: 0.7544888888888888.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:55:33,179] Trial 26 finished with value: 0.7509630756231516 and parameters: {'learning_rate': 0.052981754458349774, 'n_estimators': 700, 'subsample': 0.4, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 24 with value: 0.7544888888888888.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:55:38,472] Trial 27 finished with value: 0.7489405999155048 and parameters: {'learning_rate': 0.06215875176436657, 'n_estimators': 600, 'subsample': 0.5, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 24 with value: 0.7544888888888888.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:55:46,856] Trial 28 finished with value: 0.7563173637515843 and parameters: {'learning_rate': 0.04784752323767356, 'n_estimators': 500, 'subsample': 0.8, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 28 with value: 0.7563173637515843.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:56:02,461] Trial 29 finished with value: 0.7547950992817912 and parameters: {'learning_rate': 0.04493502429970954, 'n_estimators': 500, 'subsample': 0.8, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 28 with value: 0.7563173637515843.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:56:14,916] Trial 30 finished with value: 0.7594984368398817 and parameters: {'learning_rate': 0.0490372961854511, 'n_estimators': 400, 'subsample': 0.8, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:56:27,365] Trial 31 finished with value: 0.7593923109421208 and parameters: {'learning_rate': 0.05070363843953491, 'n_estimators': 400, 'subsample': 0.8, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:56:39,739] Trial 32 finished with value: 0.7578599070553442 and parameters: {'learning_rate': 0.04824069582609474, 'n_estimators': 400, 'subsample': 0.8, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:56:46,595] Trial 33 finished with value: 0.752054752851711 and parameters: {'learning_rate': 0.02400312445736808, 'n_estimators': 200, 'subsample': 0.9000000000000001, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:56:56,972] Trial 34 finished with value: 0.7503384875369665 and parameters: {'learning_rate': 0.04928573350534983, 'n_estimators': 400, 'subsample': 0.8, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:57:03,166] Trial 35 finished with value: 0.7535736375158428 and parameters: {'learning_rate': 0.06448806910672007, 'n_estimators': 300, 'subsample': 0.9000000000000001, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:57:13,093] Trial 36 finished with value: 0.7518141106886354 and parameters: {'learning_rate': 0.019967805368631082, 'n_estimators': 200, 'subsample': 1.0, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_depth': 8, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:57:23,598] Trial 37 finished with value: 0.7577855513307985 and parameters: {'learning_rate': 0.0330002169973392, 'n_estimators': 400, 'subsample': 0.8, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:57:30,472] Trial 38 finished with value: 0.7511178707224335 and parameters: {'learning_rate': 0.030868132493693218, 'n_estimators': 400, 'subsample': 0.7, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:57:38,471] Trial 39 finished with value: 0.7535722855935784 and parameters: {'learning_rate': 0.040628404613222924, 'n_estimators': 200, 'subsample': 0.9000000000000001, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:57:46,812] Trial 40 finished with value: 0.7516052386987748 and parameters: {'learning_rate': 0.018014520816290312, 'n_estimators': 300, 'subsample': 0.7, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:57:59,889] Trial 41 finished with value: 0.7578227291930715 and parameters: {'learning_rate': 0.043525736591197434, 'n_estimators': 500, 'subsample': 0.8, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:58:10,324] Trial 42 finished with value: 0.7561138994507816 and parameters: {'learning_rate': 0.027246043845764876, 'n_estimators': 400, 'subsample': 0.8, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 17:58:24,014] Trial 43 finished with value: 0.7582539923954372 and parameters: {'learning_rate': 0.0338498685265353, 'n_estimators': 400, 'subsample': 0.9000000000000001, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:58:42,606] Trial 44 finished with value: 0.7586764681030841 and parameters: {'learning_rate': 0.040180890690744465, 'n_estimators': 500, 'subsample': 1.0, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:58:51,760] Trial 45 finished with value: 0.7525022391212505 and parameters: {'learning_rate': 0.06408431899707769, 'n_estimators': 300, 'subsample': 1.0, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:59:02,044] Trial 46 finished with value: 0.7563498098859315 and parameters: {'learning_rate': 0.03845262801445666, 'n_estimators': 300, 'subsample': 0.9000000000000001, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:59:29,841] Trial 47 finished with value: 0.7532795944233206 and parameters: {'learning_rate': 0.02806728264691403, 'n_estimators': 500, 'subsample': 1.0, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_depth': 9, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:59:43,586] Trial 48 finished with value: 0.757576679340938 and parameters: {'learning_rate': 0.054134507796642875, 'n_estimators': 400, 'subsample': 0.9000000000000001, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 17:59:52,975] Trial 49 finished with value: 0.75128618504436 and parameters: {'learning_rate': 0.024198070376213954, 'n_estimators': 300, 'subsample': 1.0, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:00:11,183] Trial 50 finished with value: 0.754005576679341 and parameters: {'learning_rate': 0.03783577515046125, 'n_estimators': 400, 'subsample': 0.9000000000000001, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_depth': 8, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:00:24,307] Trial 51 finished with value: 0.7579565694972539 and parameters: {'learning_rate': 0.04426887646428881, 'n_estimators': 500, 'subsample': 0.8, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:00:38,162] Trial 52 finished with value: 0.7493353612167301 and parameters: {'learning_rate': 0.07082677547612322, 'n_estimators': 500, 'subsample': 0.7, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:00:58,703] Trial 53 finished with value: 0.7581999155048585 and parameters: {'learning_rate': 0.04894700168913399, 'n_estimators': 600, 'subsample': 0.9000000000000001, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:01:22,647] Trial 54 finished with value: 0.7445880861850444 and parameters: {'learning_rate': 0.07535576061089208, 'n_estimators': 600, 'subsample': 0.9000000000000001, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:01:41,370] Trial 55 finished with value: 0.7584013519222644 and parameters: {'learning_rate': 0.05523049881676749, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 30 with value: 0.7594984368398817.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:01:56,540] Trial 56 finished with value: 0.7628606675116181 and parameters: {'learning_rate': 0.058384365395123296, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:02:11,910] Trial 57 finished with value: 0.7609656104773976 and parameters: {'learning_rate': 0.0581897081086508, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:02:27,230] Trial 58 finished with value: 0.7582526404731729 and parameters: {'learning_rate': 0.05915998204675285, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:02:42,387] Trial 59 finished with value: 0.7628390367553866 and parameters: {'learning_rate': 0.07684630565242746, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:02:55,006] Trial 60 finished with value: 0.7610693705111957 and parameters: {'learning_rate': 0.07796143240795518, 'n_estimators': 500, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:03:07,646] Trial 61 finished with value: 0.7609639205745669 and parameters: {'learning_rate': 0.07689165202849878, 'n_estimators': 500, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:03:22,709] Trial 62 finished with value: 0.7590320236586396 and parameters: {'learning_rate': 0.08096278157392342, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:03:35,297] Trial 63 finished with value: 0.7567209125475285 and parameters: {'learning_rate': 0.0722952436596337, 'n_estimators': 500, 'subsample': 1.0, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:03:46,738] Trial 64 finished with value: 0.7585061258977609 and parameters: {'learning_rate': 0.07922538895995447, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:03:59,359] Trial 65 finished with value: 0.7607185466835658 and parameters: {'learning_rate': 0.06790214734600987, 'n_estimators': 500, 'subsample': 1.0, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:04:16,945] Trial 66 finished with value: 0.7564897338403042 and parameters: {'learning_rate': 0.0954709586623563, 'n_estimators': 700, 'subsample': 1.0, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:04:26,540] Trial 67 finished with value: 0.7597313054499366 and parameters: {'learning_rate': 0.07124112825707483, 'n_estimators': 500, 'subsample': 1.0, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:04:36,115] Trial 68 finished with value: 0.7572025348542459 and parameters: {'learning_rate': 0.06343407308142245, 'n_estimators': 500, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:04:47,625] Trial 69 finished with value: 0.7613144064216308 and parameters: {'learning_rate': 0.08564577337964145, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:04:59,344] Trial 70 finished with value: 0.7548559357836924 and parameters: {'learning_rate': 0.08629741904071588, 'n_estimators': 700, 'subsample': 0.9000000000000001, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:05:10,825] Trial 71 finished with value: 0.7586666666666666 and parameters: {'learning_rate': 0.06970525363971175, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:05:20,393] Trial 72 finished with value: 0.756705027460921 and parameters: {'learning_rate': 0.08314513610683427, 'n_estimators': 500, 'subsample': 1.0, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:05:35,484] Trial 73 finished with value: 0.7623002957329953 and parameters: {'learning_rate': 0.09748986636623776, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:05:50,604] Trial 74 finished with value: 0.7585960287283482 and parameters: {'learning_rate': 0.09841364378087833, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:06:08,217] Trial 75 finished with value: 0.7607570764681031 and parameters: {'learning_rate': 0.060819889023788355, 'n_estimators': 700, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:06:24,569] Trial 76 finished with value: 0.7618656527249684 and parameters: {'learning_rate': 0.05946594925795566, 'n_estimators': 700, 'subsample': 0.9000000000000001, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:06:43,310] Trial 77 finished with value: 0.7562376003379805 and parameters: {'learning_rate': 0.08714705229145421, 'n_estimators': 800, 'subsample': 0.9000000000000001, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:06:55,978] Trial 78 finished with value: 0.7591269961977186 and parameters: {'learning_rate': 0.05715231388459441, 'n_estimators': 700, 'subsample': 0.9000000000000001, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:07:17,055] Trial 79 finished with value: 0.7552506970849177 and parameters: {'learning_rate': 0.07930655618722202, 'n_estimators': 900, 'subsample': 0.9000000000000001, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:07:42,432] Trial 80 finished with value: 0.7539704267004647 and parameters: {'learning_rate': 0.09004014890906104, 'n_estimators': 800, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:08:00,205] Trial 81 finished with value: 0.7601710181664555 and parameters: {'learning_rate': 0.06020963621697479, 'n_estimators': 700, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:08:13,818] Trial 82 finished with value: 0.7593652724968314 and parameters: {'learning_rate': 0.07550904450311743, 'n_estimators': 700, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:08:29,010] Trial 83 finished with value: 0.7598864385297844 and parameters: {'learning_rate': 0.05973085432248445, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:08:44,062] Trial 84 finished with value: 0.7602392902408112 and parameters: {'learning_rate': 0.06544050036329212, 'n_estimators': 600, 'subsample': 1.0, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:08:52,997] Trial 85 finished with value: 0.7582570342205324 and parameters: {'learning_rate': 0.0903483391337539, 'n_estimators': 700, 'subsample': 0.9000000000000001, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-05 18:09:05,421] Trial 86 finished with value: 0.7549877482044782 and parameters: {'learning_rate': 0.05417116023726866, 'n_estimators': 600, 'subsample': 0.6000000000000001, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 18:09:16,286] Trial 87 finished with value: 0.7523288550908322 and parameters: {'learning_rate': 0.09999996459852539, 'n_estimators': 800, 'subsample': 1.0, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 56 with value: 0.7628606675116181.\n",
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# xgb without odds data\n",
    "optimiser = Optimiser(df, \"GBC\", verbosity=False)\n",
    "model = optimiser.optimise()\n",
    "\n",
    "model_filename = \"GBC_home_win_with_odds.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "    \n",
    "    \n",
    "# xgb without odds data\n",
    "optimiser = Optimiser(df, \"CAT\", verbosity=False)\n",
    "model = optimiser.optimise()\n",
    "\n",
    "model_filename = \"CAT_home_win_with_odds.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "808485a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.25\n",
      "Confusion Matrix:\n",
      "[[ 466  846]\n",
      " [ 110 1014]]\n",
      "Precision: 0.5451612903225806\n",
      "Recall: 0.902135231316726\n",
      "F1 Score: 0.6796246648793566\n",
      "-----------------------\n",
      "Threshold: 0.3\n",
      "Confusion Matrix:\n",
      "[[615 697]\n",
      " [164 960]]\n",
      "Precision: 0.5793602896801449\n",
      "Recall: 0.8540925266903915\n",
      "F1 Score: 0.6903991370010787\n",
      "-----------------------\n",
      "Threshold: 0.35\n",
      "Confusion Matrix:\n",
      "[[745 567]\n",
      " [224 900]]\n",
      "Precision: 0.6134969325153374\n",
      "Recall: 0.800711743772242\n",
      "F1 Score: 0.6947124662292551\n",
      "-----------------------\n",
      "Threshold: 0.4\n",
      "Confusion Matrix:\n",
      "[[854 458]\n",
      " [303 821]]\n",
      "Precision: 0.6419077404222049\n",
      "Recall: 0.7304270462633452\n",
      "F1 Score: 0.6833125260091554\n",
      "-----------------------\n",
      "Threshold: 0.45\n",
      "Confusion Matrix:\n",
      "[[954 358]\n",
      " [373 751]]\n",
      "Precision: 0.6771866546438232\n",
      "Recall: 0.6681494661921709\n",
      "F1 Score: 0.6726377071204657\n",
      "-----------------------\n",
      "Threshold: 0.5\n",
      "Confusion Matrix:\n",
      "[[1025  287]\n",
      " [ 437  687]]\n",
      "Precision: 0.7053388090349076\n",
      "Recall: 0.6112099644128114\n",
      "F1 Score: 0.6549094375595805\n",
      "-----------------------\n",
      "Threshold: 0.55\n",
      "Confusion Matrix:\n",
      "[[1089  223]\n",
      " [ 507  617]]\n",
      "Precision: 0.7345238095238096\n",
      "Recall: 0.548932384341637\n",
      "F1 Score: 0.6283095723014258\n",
      "-----------------------\n",
      "Threshold: 0.6\n",
      "Confusion Matrix:\n",
      "[[1154  158]\n",
      " [ 600  524]]\n",
      "Precision: 0.7683284457478006\n",
      "Recall: 0.46619217081850534\n",
      "F1 Score: 0.5802879291251385\n",
      "-----------------------\n",
      "Threshold: 0.65\n",
      "Confusion Matrix:\n",
      "[[1205  107]\n",
      " [ 701  423]]\n",
      "Precision: 0.7981132075471699\n",
      "Recall: 0.3763345195729537\n",
      "F1 Score: 0.5114873035066506\n",
      "-----------------------\n",
      "Threshold: 0.7\n",
      "Confusion Matrix:\n",
      "[[1241   71]\n",
      " [ 800  324]]\n",
      "Precision: 0.8202531645569621\n",
      "Recall: 0.28825622775800713\n",
      "F1 Score: 0.4265964450296248\n",
      "-----------------------\n",
      "Threshold: 0.75\n",
      "Confusion Matrix:\n",
      "[[1268   44]\n",
      " [ 887  237]]\n",
      "Precision: 0.8434163701067615\n",
      "Recall: 0.21085409252669038\n",
      "F1 Score: 0.33736654804270466\n",
      "-----------------------\n",
      "Threshold: 0.8\n",
      "Confusion Matrix:\n",
      "[[1286   26]\n",
      " [ 972  152]]\n",
      "Precision: 0.8539325842696629\n",
      "Recall: 0.13523131672597866\n",
      "F1 Score: 0.23348694316436253\n",
      "-----------------------\n",
      "Threshold: 0.85\n",
      "Confusion Matrix:\n",
      "[[1301   11]\n",
      " [1030   94]]\n",
      "Precision: 0.8952380952380953\n",
      "Recall: 0.08362989323843416\n",
      "F1 Score: 0.15296989422294546\n",
      "-----------------------\n",
      "Threshold: 0.9\n",
      "Confusion Matrix:\n",
      "[[1308    4]\n",
      " [1082   42]]\n",
      "Precision: 0.9130434782608695\n",
      "Recall: 0.037366548042704624\n",
      "F1 Score: 0.07179487179487179\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "thresholds = [0.25, 0.3, 0.35, 0.40, 0.45, 0.5, 0.55, 0.60, 0.65, .70, .75, 0.8, 0.85, 0.9]\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = []\n",
    "    for i in range(len(y_prob_test)):\n",
    "        if y_prob_test[i] >= t:\n",
    "            preds.append(1.)\n",
    "        else:\n",
    "            preds.append(0.)\n",
    "    \n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    \n",
    "    print(f\"Threshold: {t}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"-----------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f467ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profits(odds, preds, threshold, validation_set):\n",
    "\n",
    "    profit = 0\n",
    "    bets = 0\n",
    "    odds = odds.reset_index(drop = True)\n",
    "\n",
    "    for i in range(len(odds)):\n",
    "\n",
    "        if preds[i] > threshold:\n",
    "            bets += 1\n",
    "            o = odds[i]\n",
    "            bet = 1 * o \n",
    "            if validation_set[i] == 1:\n",
    "                profit += bet - 1\n",
    "            else:\n",
    "                profit += -1\n",
    "    return profit, bets, profit/bets*100\n",
    "\n",
    "def get_value_strat1(odds, preds, threshold, validation_set):\n",
    "    \n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    p1 = 0\n",
    "    odds = odds.reset_index(drop = True)\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] > 1/odds[i]:\n",
    "            if abs(preds[i] - 1/odds[i]) > threshold:\n",
    "                if validation_set[i] == 1:\n",
    "                    o = odds[i]\n",
    "                    p1 += (1 * o)\n",
    "                    c1 += 1\n",
    "                else:\n",
    "                    c2 += 1\n",
    "                    p1 += -1\n",
    "                    \n",
    "    return p1, c1, c2, (p1/(c1+c2))*100\n",
    "\n",
    "def get_value_strat2(odds, preds, threshold, validation_set):\n",
    "    \n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    p1 = 0\n",
    "    odds = odds.reset_index(drop = True)\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] < 1/odds[i]:\n",
    "            if abs(preds[i] - 1/odds[i]) > threshold:\n",
    "                if validation_set[i] == 0:\n",
    "                    p = 1 - (1/odds[i])\n",
    "                    p1 += (1 * (1/p)) - 1\n",
    "                    c1 += 1\n",
    "                else:\n",
    "                    c2 += 1\n",
    "                    p1 += -1\n",
    "                    \n",
    "    return p1, c1, c2, (p1/(c1+c2))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a01d365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold 0.25 for predictions: \n",
      " Profit: 83.20433333333328 \n",
      " Number of bets: 1860 \n",
      " Return %: 4.473351254480284 \n",
      "\n",
      "At threshold 0.3 for predictions: \n",
      " Profit: 124.12099999999995 \n",
      " Number of bets: 1657 \n",
      " Return %: 7.490706095353045 \n",
      "\n",
      "At threshold 0.35 for predictions: \n",
      " Profit: 146.62933333333334 \n",
      " Number of bets: 1467 \n",
      " Return %: 9.995182912974323 \n",
      "\n",
      "At threshold 0.4 for predictions: \n",
      " Profit: 139.781 \n",
      " Number of bets: 1279 \n",
      " Return %: 10.928928850664581 \n",
      "\n",
      "At threshold 0.45 for predictions: \n",
      " Profit: 143.16933333333338 \n",
      " Number of bets: 1109 \n",
      " Return %: 12.909768560264506 \n",
      "\n",
      "At threshold 0.5 for predictions: \n",
      " Profit: 134.03266666666678 \n",
      " Number of bets: 974 \n",
      " Return %: 13.761054072553058 \n",
      "\n",
      "At threshold 0.55 for predictions: \n",
      " Profit: 124.90433333333337 \n",
      " Number of bets: 840 \n",
      " Return %: 14.869563492063495 \n",
      "\n",
      "At threshold 0.6 for predictions: \n",
      " Profit: 98.78766666666671 \n",
      " Number of bets: 682 \n",
      " Return %: 14.484995112414472 \n",
      "\n",
      "At threshold 0.65 for predictions: \n",
      " Profit: 68.6933333333333 \n",
      " Number of bets: 530 \n",
      " Return %: 12.96100628930817 \n",
      "\n",
      "At threshold 0.7 for predictions: \n",
      " Profit: 44.23333333333332 \n",
      " Number of bets: 395 \n",
      " Return %: 11.198312236286917 \n",
      "\n",
      "At threshold 0.75 for predictions: \n",
      " Profit: 26.15999999999999 \n",
      " Number of bets: 281 \n",
      " Return %: 9.309608540925263 \n",
      "\n",
      "At threshold 0.8 for predictions: \n",
      " Profit: 9.486666666666665 \n",
      " Number of bets: 178 \n",
      " Return %: 5.329588014981272 \n",
      "\n",
      "At threshold 0.85 for predictions: \n",
      " Profit: 6.345000000000001 \n",
      " Number of bets: 105 \n",
      " Return %: 6.042857142857144 \n",
      "\n",
      "At threshold 0.9 for predictions: \n",
      " Profit: 1.6100000000000019 \n",
      " Number of bets: 46 \n",
      " Return %: 3.500000000000004 \n",
      "\n",
      "(42.56166666666667, 41, 4, 94.58148148148149)\n",
      "(13.83125861624821, 1308, 1082, 0.5787137496338163)\n"
     ]
    }
   ],
   "source": [
    "validation_set = y_test.reset_index(drop = True)\n",
    "\n",
    "for t in [0.25, 0.3, 0.35, 0.40, 0.45, 0.5, 0.55, 0.60, 0.65, .70, .75, 0.8, 0.85, 0.9]:\n",
    "    results = get_profits(odds, y_prob_test, t, validation_set)\n",
    "    print(f\"At threshold {t} for predictions: \\n Profit: {results[0]} \\n Number of bets: {results[1]} \\n Return %: {results[2]} \\n\")\n",
    "\n",
    "print(get_value_strat1(odds, preds, 0.05, validation_set))\n",
    "print(get_value_strat2(odds, preds, 0.05, validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5e95aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  [0.71822199 0.71016376 0.71380296 0.70280811 0.70826833]\n",
      "Mean:  0.7106530323079312\n",
      "Std:  0.005189993417007074\n"
     ]
    }
   ],
   "source": [
    "X_train = train[features]\n",
    "X_test = test[features]\n",
    "y_train = train['home_win']\n",
    "y_test = test['home_win']\n",
    "\n",
    "model = LGBMClassifier()\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold, verbose=True)\n",
    "\n",
    "print(\"Results: \", results)\n",
    "print(\"Mean: \", results.mean())\n",
    "print(\"Std: \", results.std())\n",
    "\n",
    "cv_results = cross_validate(model, X_train, y_train, cv=kfold, return_estimator=True)\n",
    "trained_models = cv_results['estimator']\n",
    "trained_model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b21ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:41,832] A new study created in memory with name: no-name-b801ac68-d7b6-4f9d-8fd9-f0afa4402172\n",
      "[I 2023-06-30 16:35:42,958] Trial 0 finished with value: 0.6799594219251801 and parameters: {'max_depth': 6, 'learning_rate': 0.0033957085450997343, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.5, 'reg_lambda': 7.483684930461474e-05, 'reg_alpha': 0.0001549762589105797}. Best is trial 0 with value: 0.6799594219251801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68842365 0.62812347 0.69901854 0.67995942]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:43,339] Trial 1 finished with value: 0.6889891285478691 and parameters: {'max_depth': 4, 'learning_rate': 0.08191744158464657, 'n_estimators': 600, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_lambda': 0.00013597601715941752, 'reg_alpha': 9.930740700875111e-05}. Best is trial 1 with value: 0.6889891285478691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69499179 0.64903165 0.6918429  0.68898913]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:44,016] Trial 2 finished with value: 0.6851727280618002 and parameters: {'max_depth': 4, 'learning_rate': 0.0047852502965763585, 'n_estimators': 800, 'subsample': 0.6000000000000001, 'colsample_bytree': 1.0, 'reg_lambda': 0.0017487553352383877, 'reg_alpha': 0.0023592832532525376}. Best is trial 1 with value: 0.6889891285478691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69252874 0.63903614 0.69716088 0.68517273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:44,363] Trial 3 finished with value: 0.677293095217429 and parameters: {'max_depth': 3, 'learning_rate': 0.007422600299561091, 'n_estimators': 600, 'subsample': 0.5, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.00015120875736949062, 'reg_alpha': 1.2503327553343988}. Best is trial 1 with value: 0.6889891285478691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68513957 0.62785056 0.6905016  0.6772931 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:44,756] Trial 4 finished with value: 0.6854927957642567 and parameters: {'max_depth': 7, 'learning_rate': 0.04094635884167254, 'n_estimators': 300, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.2, 'reg_lambda': 0.0013117207229135952, 'reg_alpha': 0.0006033914190677552}. Best is trial 1 with value: 0.6889891285478691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69211823 0.64251668 0.69199179 0.6854928 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:45,081] Trial 5 finished with value: 0.6645826100164917 and parameters: {'max_depth': 5, 'learning_rate': 0.012377798476398118, 'n_estimators': 300, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.0018515502828461874, 'reg_alpha': 0.4122022692771079}. Best is trial 1 with value: 0.6889891285478691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67364532 0.60740741 0.68257492 0.66458261]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:45,454] Trial 6 finished with value: 0.6545398077423835 and parameters: {'max_depth': 8, 'learning_rate': 0.006440644442267904, 'n_estimators': 300, 'subsample': 0.8, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 0.0002799296477872034, 'reg_alpha': 7.068318036222236e-05}. Best is trial 1 with value: 0.6889891285478691.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66502463 0.58829465 0.67948718 0.65453981]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:45,756] Trial 7 finished with value: 0.6899981555420536 and parameters: {'max_depth': 8, 'learning_rate': 0.009378726488492506, 'n_estimators': 200, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.7, 'reg_lambda': 0.003956366738154925, 'reg_alpha': 4.427223377366792e-05}. Best is trial 7 with value: 0.6899981555420536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69827586 0.6405868  0.7111835  0.68999816]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:46,144] Trial 8 finished with value: 0.6519874034372016 and parameters: {'max_depth': 4, 'learning_rate': 0.0014457303557080588, 'n_estimators': 500, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.0022032471543014936, 'reg_alpha': 7.942084067850918e-05}. Best is trial 7 with value: 0.6899981555420536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66584565 0.56609808 0.70611702 0.6519874 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:46,792] Trial 9 finished with value: 0.6917178413332176 and parameters: {'max_depth': 5, 'learning_rate': 0.009190384943585584, 'n_estimators': 600, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 0.0018107948397834812, 'reg_alpha': 4.248323067535345}. Best is trial 9 with value: 0.6917178413332176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69868637 0.64813039 0.7027027  0.69171784]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:47,164] Trial 10 finished with value: 0.6776145191389636 and parameters: {'max_depth': 1, 'learning_rate': 0.02294848657201316, 'n_estimators': 1000, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_lambda': 0.13910813905473401, 'reg_alpha': 9.446081579068625}. Best is trial 9 with value: 0.6917178413332176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68431856 0.63328565 0.68242549 0.67761452]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:47,371] Trial 11 finished with value: 0.6911400920059022 and parameters: {'max_depth': 10, 'learning_rate': 0.01652114988674931, 'n_estimators': 100, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_lambda': 0.0839403034426011, 'reg_alpha': 0.02234717587975891}. Best is trial 9 with value: 0.6917178413332176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6999179  0.639724   0.71712707 0.69114009]\n",
      "[0.70155993 0.64380206 0.71646674 0.69317442]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:47,568] Trial 12 finished with value: 0.6931744206232098 and parameters: {'max_depth': 10, 'learning_rate': 0.018668609363599566, 'n_estimators': 100, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_lambda': 0.06309790619756439, 'reg_alpha': 0.053108472523400986}. Best is trial 12 with value: 0.6931744206232098.\n",
      "[I 2023-06-30 16:35:48,276] Trial 13 finished with value: 0.7006146384862425 and parameters: {'max_depth': 10, 'learning_rate': 0.02885435722554123, 'n_estimators': 500, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 2.9449961864760237, 'reg_alpha': 0.03988166259073895}. Best is trial 13 with value: 0.7006146384862425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70689655 0.66096866 0.70875764 0.70061464]\n",
      "[0.70073892 0.64833575 0.7081138  0.69336836]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:48,480] Trial 14 finished with value: 0.693368359951393 and parameters: {'max_depth': 10, 'learning_rate': 0.03032823316922083, 'n_estimators': 100, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 7.088735634377983, 'reg_alpha': 0.07149214466439999}. Best is trial 13 with value: 0.7006146384862425.\n",
      "[I 2023-06-30 16:35:49,082] Trial 15 finished with value: 0.7003596692995399 and parameters: {'max_depth': 9, 'learning_rate': 0.03308930217106253, 'n_estimators': 400, 'subsample': 0.2, 'colsample_bytree': 0.8, 'reg_lambda': 8.845408380534133, 'reg_alpha': 0.12941820089529577}. Best is trial 13 with value: 0.7006146384862425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70689655 0.65967588 0.71047228 0.70035967]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:49,643] Trial 16 finished with value: 0.7063975566357087 and parameters: {'max_depth': 8, 'learning_rate': 0.051780452131762605, 'n_estimators': 400, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 9.06826688759588, 'reg_alpha': 0.009826364138760217}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71223317 0.66918358 0.71256281 0.70639756]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:50,528] Trial 17 finished with value: 0.6912784263518792 and parameters: {'max_depth': 8, 'learning_rate': 0.06886892442180567, 'n_estimators': 700, 'subsample': 0.4, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.3870772029900902, 'reg_alpha': 0.005264750673450992}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69663383 0.65418811 0.69002962 0.69127843]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:51,067] Trial 18 finished with value: 0.7005536086277233 and parameters: {'max_depth': 7, 'learning_rate': 0.05510805060732313, 'n_estimators': 400, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.1691704662358575, 'reg_alpha': 0.009427996595692356}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70607553 0.66384977 0.7027833  0.70055361]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:51,735] Trial 19 finished with value: 0.6915320393195035 and parameters: {'max_depth': 9, 'learning_rate': 0.0899798508338393, 'n_estimators': 500, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 1.59420602736326, 'reg_alpha': 0.0015148200945954986}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69704433 0.65384615 0.69146825 0.69153204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:52,286] Trial 20 finished with value: 0.6954067572259353 and parameters: {'max_depth': 9, 'learning_rate': 0.05021501266808442, 'n_estimators': 400, 'subsample': 0.2, 'colsample_bytree': 1.0, 'reg_lambda': 0.3284727218679044, 'reg_alpha': 1.2681541396545948e-05}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70114943 0.65725047 0.698      0.69540676]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:52,811] Trial 21 finished with value: 0.6907074581199548 and parameters: {'max_depth': 7, 'learning_rate': 0.05593717596482994, 'n_estimators': 400, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.6981754884689602, 'reg_alpha': 0.014428506980925812}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69581281 0.65454545 0.68756121 0.69070746]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:53,439] Trial 22 finished with value: 0.6971237305789427 and parameters: {'max_depth': 7, 'learning_rate': 0.0984413006190074, 'n_estimators': 500, 'subsample': 0.2, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 5.836175020709964, 'reg_alpha': 0.005374484555205109}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70238095 0.66105657 0.69655172 0.69712373]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:54,246] Trial 23 finished with value: 0.7038573583022307 and parameters: {'max_depth': 6, 'learning_rate': 0.04839195208563363, 'n_estimators': 700, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 0.6334458202534671, 'reg_alpha': 0.01786509872825797}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70935961 0.66760563 0.70675944 0.70385736]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:55,062] Trial 24 finished with value: 0.6990916044614183 and parameters: {'max_depth': 6, 'learning_rate': 0.03240647048175348, 'n_estimators': 700, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 0.02789555969479975, 'reg_alpha': 0.022018038458405498}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70484401 0.66132831 0.7027027  0.6990916 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:55,965] Trial 25 finished with value: 0.6934375271243816 and parameters: {'max_depth': 9, 'learning_rate': 0.04270073605959379, 'n_estimators': 700, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_lambda': 0.40672026280555174, 'reg_alpha': 0.21821550462669084}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69909688 0.65538317 0.69491525 0.69343753]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:57,059] Trial 26 finished with value: 0.7030287084454474 and parameters: {'max_depth': 8, 'learning_rate': 0.027374607352472314, 'n_estimators': 800, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 3.8107192174707376, 'reg_alpha': 0.07917864615758582}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70935961 0.6634981  0.7122449  0.70302871]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:57,951] Trial 27 finished with value: 0.6937562386077597 and parameters: {'max_depth': 6, 'learning_rate': 0.06568977505417774, 'n_estimators': 800, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 0.44267142881856414, 'reg_alpha': 0.3345675560054851}. Best is trial 16 with value: 0.7063975566357087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69909688 0.65699579 0.69299112 0.69375624]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:35:59,147] Trial 28 finished with value: 0.7067135556809304 and parameters: {'max_depth': 8, 'learning_rate': 0.021666346746337602, 'n_estimators': 900, 'subsample': 0.5, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 9.817098592636615, 'reg_alpha': 0.10422672062405058}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71305419 0.66761769 0.71705822 0.70671356]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:00,222] Trial 29 finished with value: 0.6936897838729277 and parameters: {'max_depth': 6, 'learning_rate': 0.01940279995397545, 'n_estimators': 900, 'subsample': 0.7, 'colsample_bytree': 0.4, 'reg_lambda': 4.058221787446444, 'reg_alpha': 0.0003783261055181683}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6999179  0.65339023 0.69949239 0.69368978]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:00,657] Trial 30 finished with value: 0.6823748481034632 and parameters: {'max_depth': 2, 'learning_rate': 0.013698669967848303, 'n_estimators': 1000, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 7.988535814476174, 'reg_alpha': 0.03389053222594849}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69047619 0.63255361 0.69935345 0.68237485]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:01,812] Trial 31 finished with value: 0.6957241124902352 and parameters: {'max_depth': 8, 'learning_rate': 0.021214950089914118, 'n_estimators': 900, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_lambda': 2.7201914671311758, 'reg_alpha': 0.09837732824914658}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70155993 0.65723715 0.69909729 0.69572411]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:02,789] Trial 32 finished with value: 0.700743479298672 and parameters: {'max_depth': 7, 'learning_rate': 0.04041015268015262, 'n_estimators': 800, 'subsample': 0.4, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 8.269851928924536, 'reg_alpha': 0.011634855394857297}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70648604 0.66321244 0.7047047  0.70074348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:03,839] Trial 33 finished with value: 0.7001074125509938 and parameters: {'max_depth': 8, 'learning_rate': 0.026560568342111783, 'n_estimators': 800, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_lambda': 0.9270728008745543, 'reg_alpha': 0.051789099091578694}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70607553 0.66162571 0.70564516 0.70010741]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:04,714] Trial 34 finished with value: 0.6923593329572086 and parameters: {'max_depth': 5, 'learning_rate': 0.06814296877160232, 'n_estimators': 900, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.5, 'reg_lambda': 2.9355889850722594, 'reg_alpha': 0.13691655562111235}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69745484 0.65641026 0.68952008 0.69235933]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:05,666] Trial 35 finished with value: 0.6952806288516622 and parameters: {'max_depth': 9, 'learning_rate': 0.03765649037580498, 'n_estimators': 700, 'subsample': 0.5, 'colsample_bytree': 0.4, 'reg_lambda': 3.554256058291242, 'reg_alpha': 0.6470828565307712}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70073892 0.65822785 0.69573835 0.69528063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:06,448] Trial 36 finished with value: 0.6943231381824494 and parameters: {'max_depth': 7, 'learning_rate': 0.023281066199325486, 'n_estimators': 600, 'subsample': 0.7, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 9.84078513767068, 'reg_alpha': 0.0027982618852927217}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70114943 0.65167464 0.70496894 0.69432314]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:07,201] Trial 37 finished with value: 0.6990916044614183 and parameters: {'max_depth': 4, 'learning_rate': 0.04539871615539839, 'n_estimators': 1000, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.4, 'reg_lambda': 0.6671824105211022, 'reg_alpha': 0.16132178998349925}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70484401 0.66132831 0.7027027  0.6990916 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:08,320] Trial 38 finished with value: 0.7034098060064231 and parameters: {'max_depth': 8, 'learning_rate': 0.01570375448085569, 'n_estimators': 800, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 0.23890955349236268, 'reg_alpha': 0.03070952254511473}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70977011 0.6638136  0.71297242 0.70340981]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:09,237] Trial 39 finished with value: 0.6984528252755837 and parameters: {'max_depth': 5, 'learning_rate': 0.015804428849966707, 'n_estimators': 900, 'subsample': 0.5, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.1676501679529765, 'reg_alpha': 0.021393319878630034}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70525452 0.65645933 0.71014493 0.69845283]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:09,650] Trial 40 finished with value: 0.682948528773544 and parameters: {'max_depth': 3, 'learning_rate': 0.013701406405143906, 'n_estimators': 700, 'subsample': 0.30000000000000004, 'colsample_bytree': 1.0, 'reg_lambda': 0.6497067806102498, 'reg_alpha': 0.007132107082485867}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69047619 0.63574879 0.69556025 0.68294853]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:10,703] Trial 41 finished with value: 0.6970586320631891 and parameters: {'max_depth': 8, 'learning_rate': 0.024158325962121308, 'n_estimators': 800, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 2.8109520362735188, 'reg_alpha': 0.035186255290502}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70279146 0.65913371 0.7        0.69705863]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:11,807] Trial 42 finished with value: 0.703091094523045 and parameters: {'max_depth': 8, 'learning_rate': 0.01236335203326929, 'n_estimators': 800, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 2.0795622890548686, 'reg_alpha': 0.08968071774790792}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70977011 0.66220736 0.71517028 0.70309109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:12,635] Trial 43 finished with value: 0.6936870714347713 and parameters: {'max_depth': 7, 'learning_rate': 0.010825138107007507, 'n_estimators': 600, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.8, 'reg_lambda': 0.8909978671583662, 'reg_alpha': 0.26225966765758135}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70073892 0.650024   0.70594369 0.69368707]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:13,951] Trial 44 finished with value: 0.6889877723287908 and parameters: {'max_depth': 8, 'learning_rate': 0.006760532573247477, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 1.7832562453833654, 'reg_alpha': 0.8607677328688312}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6954023  0.6473384  0.69489796 0.68898777]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:15,118] Trial 45 finished with value: 0.6974370171860081 and parameters: {'max_depth': 9, 'learning_rate': 0.008320209226774844, 'n_estimators': 800, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.7, 'reg_lambda': 0.26447620726234844, 'reg_alpha': 0.015186445014563713}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70402299 0.65617549 0.70709147 0.69743702]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:15,400] Trial 46 finished with value: 0.6540949678847323 and parameters: {'max_depth': 6, 'learning_rate': 0.010742193079549066, 'n_estimators': 200, 'subsample': 0.5, 'colsample_bytree': 0.2, 'reg_lambda': 0.5808971923340446, 'reg_alpha': 0.07672411605458569}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66461412 0.58758203 0.67911319 0.65409497]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:16,209] Trial 47 finished with value: 0.6989614074299106 and parameters: {'max_depth': 7, 'learning_rate': 0.016530687148895745, 'n_estimators': 600, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'reg_lambda': 0.17204638953458373, 'reg_alpha': 0.033192667247457126}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70566502 0.65742953 0.71001032 0.69896141]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:17,605] Trial 48 finished with value: 0.6819964629806441 and parameters: {'max_depth': 8, 'learning_rate': 0.004501193352453019, 'n_estimators': 1000, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_lambda': 4.6632053750977045, 'reg_alpha': 0.48970690963940183}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68924466 0.63588264 0.6921466  0.68199646]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:18,425] Trial 49 finished with value: 0.7064599427133061 and parameters: {'max_depth': 6, 'learning_rate': 0.033897390991186965, 'n_estimators': 700, 'subsample': 0.4, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 1.5409931272979087, 'reg_alpha': 0.12835983057194006}. Best is trial 28 with value: 0.7067135556809304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71264368 0.66793169 0.71544715 0.70645994]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:19,281] Trial 50 finished with value: 0.7070322671643086 and parameters: {'max_depth': 6, 'learning_rate': 0.034777988696943526, 'n_estimators': 700, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 1.123937079562094, 'reg_alpha': 0.28933686530206554}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71305419 0.66919072 0.7148635  0.70703227]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:20,140] Trial 51 finished with value: 0.7020142565749501 and parameters: {'max_depth': 6, 'learning_rate': 0.03615325083896145, 'n_estimators': 700, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 0.9110782936808016, 'reg_alpha': 1.4878285258988722}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70771757 0.66478343 0.706      0.70201426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:20,582] Trial 52 finished with value: 0.6973705624511761 and parameters: {'max_depth': 4, 'learning_rate': 0.03089188446074245, 'n_estimators': 600, 'subsample': 0.2, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 1.2231788859732668, 'reg_alpha': 0.26998107407723243}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70484401 0.65248913 0.71428571 0.69737056]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:21,281] Trial 53 finished with value: 0.694134623730579 and parameters: {'max_depth': 5, 'learning_rate': 0.050273535661902465, 'n_estimators': 700, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 5.400689562136068, 'reg_alpha': 0.15598080880463805}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70032841 0.65402844 0.69979716 0.69413462]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:21,821] Trial 54 finished with value: 0.6909570024303445 and parameters: {'max_depth': 5, 'learning_rate': 0.04083742357471448, 'n_estimators': 500, 'subsample': 0.2, 'colsample_bytree': 0.5, 'reg_lambda': 1.5650002312482192, 'reg_alpha': 0.052050547698880234}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69745484 0.64921466 0.69805527 0.690957  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:22,201] Trial 55 finished with value: 0.696741276798889 and parameters: {'max_depth': 7, 'learning_rate': 0.07776589087140232, 'n_estimators': 300, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'reg_lambda': 0.331017539398628, 'reg_alpha': 0.022696042336936645}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70238095 0.65914433 0.69890329 0.69674128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:22,930] Trial 56 finished with value: 0.7064599427133061 and parameters: {'max_depth': 6, 'learning_rate': 0.03465155626049339, 'n_estimators': 600, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 6.028963764790881, 'reg_alpha': 0.0084826451680447}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71264368 0.66793169 0.71544715 0.70645994]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:23,646] Trial 57 finished with value: 0.6954691433035327 and parameters: {'max_depth': 6, 'learning_rate': 0.03641755558552703, 'n_estimators': 600, 'subsample': 0.2, 'colsample_bytree': 0.5, 'reg_lambda': 5.824899546503514, 'reg_alpha': 0.008853250276034173}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70155993 0.65593942 0.70070779 0.69546914]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:24,216] Trial 58 finished with value: 0.6844132453780054 and parameters: {'max_depth': 6, 'learning_rate': 0.06120002335376055, 'n_estimators': 500, 'subsample': 0.4, 'colsample_bytree': 0.30000000000000004, 'reg_lambda': 9.562772847015012, 'reg_alpha': 0.003923824910123514}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6908867  0.64194009 0.68947906 0.68441325]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:24,595] Trial 59 finished with value: 0.6978805008245812 and parameters: {'max_depth': 6, 'learning_rate': 0.02755049687726117, 'n_estimators': 300, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 2.4841666609008604, 'reg_alpha': 0.002048574338826654}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70484401 0.65515588 0.710718   0.6978805 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:25,307] Trial 60 finished with value: 0.7005522524086452 and parameters: {'max_depth': 5, 'learning_rate': 0.04988105340365471, 'n_estimators': 700, 'subsample': 0.4, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 4.598057014733462, 'reg_alpha': 0.012840804407536032}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70648604 0.66225791 0.70594159 0.70055225]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:26,191] Trial 61 finished with value: 0.6991539905390158 and parameters: {'max_depth': 7, 'learning_rate': 0.03193258430802692, 'n_estimators': 700, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 2.229760879555247, 'reg_alpha': 0.05013071759739925}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70525452 0.66003788 0.70546559 0.69915399]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:26,916] Trial 62 finished with value: 0.6985816660880132 and parameters: {'max_depth': 6, 'learning_rate': 0.021063636222428656, 'n_estimators': 600, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 1.1308900111613542, 'reg_alpha': 0.006960134152515835}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70484401 0.65875653 0.70600203 0.69858167]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:27,912] Trial 63 finished with value: 0.7048107803142089 and parameters: {'max_depth': 7, 'learning_rate': 0.047436405512429614, 'n_estimators': 800, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 6.393147329698842, 'reg_alpha': 0.01714992553296061}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71018062 0.66916589 0.70693069 0.70481078]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:28,797] Trial 64 finished with value: 0.6927377180800277 and parameters: {'max_depth': 7, 'learning_rate': 0.04553487570249262, 'n_estimators': 700, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 6.243429458240713, 'reg_alpha': 0.004575407662174054}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69868637 0.65344665 0.69617706 0.69273772]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:29,788] Trial 65 finished with value: 0.6992204452738477 and parameters: {'max_depth': 7, 'learning_rate': 0.05709291860860947, 'n_estimators': 800, 'subsample': 0.5, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 6.358835130501796, 'reg_alpha': 0.01608462940468774}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7044335  0.6635514  0.6988189  0.69922045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:30,512] Trial 66 finished with value: 0.7053817485461331 and parameters: {'max_depth': 6, 'learning_rate': 0.03668022835461691, 'n_estimators': 600, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 3.816613850827075, 'reg_alpha': 0.009432286234831692}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71100164 0.66886171 0.70958084 0.70538175]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:31,033] Trial 67 finished with value: 0.6911482293203713 and parameters: {'max_depth': 5, 'learning_rate': 0.039758018481796505, 'n_estimators': 500, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.8, 'reg_lambda': 4.23673110781861, 'reg_alpha': 0.0012497492210784666}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69745484 0.65021357 0.69684639 0.69114823]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:31,557] Trial 68 finished with value: 0.70487045395365 and parameters: {'max_depth': 6, 'learning_rate': 0.03365307175184717, 'n_estimators': 400, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 3.7073071148271337, 'reg_alpha': 0.009947893528288641}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71141215 0.66475918 0.71634121 0.70487045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:31,874] Trial 69 finished with value: 0.6945753949309956 and parameters: {'max_depth': 4, 'learning_rate': 0.025826967096664835, 'n_estimators': 400, 'subsample': 0.5, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 3.7728872052691047, 'reg_alpha': 0.00787368541514867}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70197044 0.6496139  0.70991561 0.69457539]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:32,205] Trial 70 finished with value: 0.6927350056418715 and parameters: {'max_depth': 5, 'learning_rate': 0.03539325631824659, 'n_estimators': 300, 'subsample': 0.6000000000000001, 'colsample_bytree': 1.0, 'reg_lambda': 1.7964290282959885, 'reg_alpha': 0.010218273687560092}. Best is trial 50 with value: 0.7070322671643086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69950739 0.6500956  0.70247934 0.69273501]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:32,943] Trial 71 finished with value: 0.7097623361687353 and parameters: {'max_depth': 6, 'learning_rate': 0.031881364207890645, 'n_estimators': 600, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 6.550787086628024, 'reg_alpha': 0.004353727025251494}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71633826 0.67016706 0.72296601 0.70976234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:33,550] Trial 72 finished with value: 0.698897665133235 and parameters: {'max_depth': 6, 'learning_rate': 0.029308090141345267, 'n_estimators': 500, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.8, 'reg_lambda': 2.783230575964496, 'reg_alpha': 0.0032807954874742038}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70566502 0.65710187 0.71044467 0.69889767]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:34,107] Trial 73 finished with value: 0.7023288994010937 and parameters: {'max_depth': 6, 'learning_rate': 0.0337326784407107, 'n_estimators': 400, 'subsample': 0.7, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 9.959803260782476, 'reg_alpha': 0.006196003073826274}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7089491  0.66157518 0.71369722 0.7023289 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:34,840] Trial 74 finished with value: 0.7053152938113012 and parameters: {'max_depth': 6, 'learning_rate': 0.02342072942568648, 'n_estimators': 600, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 3.435061064589308, 'reg_alpha': 0.0041551582054232}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71182266 0.66539561 0.71663244 0.70531529]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:35,495] Trial 75 finished with value: 0.6927363618609496 and parameters: {'max_depth': 5, 'learning_rate': 0.023719103966071953, 'n_estimators': 600, 'subsample': 0.9000000000000001, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 6.854504508431268, 'reg_alpha': 0.004531048974810355}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69909688 0.65178147 0.69928644 0.69273636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:35,743] Trial 76 finished with value: 0.6776145191389636 and parameters: {'max_depth': 1, 'learning_rate': 0.026750079046907467, 'n_estimators': 600, 'subsample': 0.2, 'colsample_bytree': 0.7, 'reg_lambda': 2.128698026019208, 'reg_alpha': 0.0021555780503499833}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68431856 0.63328565 0.68242549 0.67761452]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:36,385] Trial 77 finished with value: 0.6988339228365593 and parameters: {'max_depth': 6, 'learning_rate': 0.020112766747662658, 'n_estimators': 500, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 1.467839521058236, 'reg_alpha': 0.00522288659747846}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70566502 0.65677358 0.71088083 0.69883392]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:36,824] Trial 78 finished with value: 0.7006119260480862 and parameters: {'max_depth': 4, 'learning_rate': 0.041859676572609056, 'n_estimators': 600, 'subsample': 0.5, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 3.434854913148276, 'reg_alpha': 0.0012206688781284047}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70771757 0.65769231 0.71548117 0.70061193]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:37,725] Trial 79 finished with value: 0.7004234115962156 and parameters: {'max_depth': 10, 'learning_rate': 0.01817963461062786, 'n_estimators': 600, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 9.934007429660136, 'reg_alpha': 0.024050271091911136}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70689655 0.66       0.71004098 0.70042341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:38,345] Trial 80 finished with value: 0.6946418496658276 and parameters: {'max_depth': 5, 'learning_rate': 0.03145728665670001, 'n_estimators': 600, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'reg_lambda': 4.2747742914184945, 'reg_alpha': 0.003537980320290991}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70114943 0.65333333 0.70286885 0.69464185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:38,631] Trial 81 finished with value: 0.6929235200937419 and parameters: {'max_depth': 6, 'learning_rate': 0.030166895805357242, 'n_estimators': 200, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 3.04449763042967, 'reg_alpha': 0.010435175453641378}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70032841 0.6476834  0.70780591 0.69292352]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:39,284] Trial 82 finished with value: 0.7025825123687179 and parameters: {'max_depth': 6, 'learning_rate': 0.02373530517159475, 'n_estimators': 500, 'subsample': 0.5, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 4.70459421214177, 'reg_alpha': 0.01204215601081491}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70935961 0.66124402 0.71532091 0.70258251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:39,830] Trial 83 finished with value: 0.6973746311084108 and parameters: {'max_depth': 7, 'learning_rate': 0.03617726673815298, 'n_estimators': 400, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 6.629130129507466, 'reg_alpha': 0.10969271982841326}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70361248 0.65749526 0.70426829 0.69737463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:40,354] Trial 84 finished with value: 0.7063975566357087 and parameters: {'max_depth': 6, 'learning_rate': 0.04116033286788235, 'n_estimators': 400, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.7, 'reg_lambda': 2.3109516183163548, 'reg_alpha': 0.0059335106549634085}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71223317 0.66918358 0.71256281 0.70639756]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:41,227] Trial 85 finished with value: 0.7003623817376964 and parameters: {'max_depth': 7, 'learning_rate': 0.053987124389407254, 'n_estimators': 700, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 2.549749634227807, 'reg_alpha': 0.0026908021323015004}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70607553 0.66290019 0.704      0.70036238]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:41,826] Trial 86 finished with value: 0.7026476108844718 and parameters: {'max_depth': 6, 'learning_rate': 0.042335750165921095, 'n_estimators': 500, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.7, 'reg_lambda': 1.3978727735700547, 'reg_alpha': 0.006493046330977499}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7089491  0.6631829  0.71151886 0.70264761]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:42,360] Trial 87 finished with value: 0.6969284350316812 and parameters: {'max_depth': 5, 'learning_rate': 0.03923301237581104, 'n_estimators': 500, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 1.910516524514005, 'reg_alpha': 0.06219424034033487}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70361248 0.65520535 0.70721649 0.69692844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:43,337] Trial 88 finished with value: 0.69616623990973 and parameters: {'max_depth': 9, 'learning_rate': 0.02588646818891023, 'n_estimators': 700, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_lambda': 5.251905440171608, 'reg_alpha': 0.20760406771632087}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70279146 0.65458015 0.70576132 0.69616624]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:43,938] Trial 89 finished with value: 0.6940708814339033 and parameters: {'max_depth': 7, 'learning_rate': 0.02173092527546343, 'n_estimators': 400, 'subsample': 0.4, 'colsample_bytree': 1.0, 'reg_lambda': 7.35365101358397, 'reg_alpha': 0.02688407994616989}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70032841 0.65370019 0.70020325 0.69407088]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:44,759] Trial 90 finished with value: 0.7037312299279577 and parameters: {'max_depth': 6, 'learning_rate': 0.0452920649292249, 'n_estimators': 600, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7, 'reg_lambda': 0.9199974090230842, 'reg_alpha': 0.0370277274506562}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7089491  0.6685367  0.7044335  0.70373123]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:45,278] Trial 91 finished with value: 0.7027086407429911 and parameters: {'max_depth': 6, 'learning_rate': 0.034259198846812604, 'n_estimators': 400, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 3.4939860101298525, 'reg_alpha': 0.009396734961270744}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70977011 0.66025949 0.71786834 0.70270864]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:45,799] Trial 92 finished with value: 0.6994062472875618 and parameters: {'max_depth': 6, 'learning_rate': 0.02908904612859085, 'n_estimators': 400, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 3.463079572917764, 'reg_alpha': 0.004499107534044796}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70607553 0.65807068 0.71030928 0.69940625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:46,058] Trial 93 finished with value: 0.6870768596476 and parameters: {'max_depth': 3, 'learning_rate': 0.03377550950382973, 'n_estimators': 400, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 2.025036817662758, 'reg_alpha': 0.013886618643261371}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69499179 0.63879436 0.70418006 0.68707686]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:46,677] Trial 94 finished with value: 0.7039821304574255 and parameters: {'max_depth': 6, 'learning_rate': 0.03893140719653088, 'n_estimators': 500, 'subsample': 0.4, 'colsample_bytree': 0.7, 'reg_lambda': 7.840808461770476, 'reg_alpha': 0.0070457555592607374}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71018062 0.66508539 0.71239837 0.70398213]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:47,023] Trial 95 finished with value: 0.6854914395451783 and parameters: {'max_depth': 5, 'learning_rate': 0.028368802677727113, 'n_estimators': 300, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_lambda': 5.23922507989078, 'reg_alpha': 0.01951343879151807}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69252874 0.64076739 0.69510926 0.68549144]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:47,733] Trial 96 finished with value: 0.6939474654977866 and parameters: {'max_depth': 6, 'learning_rate': 0.052700157765101174, 'n_estimators': 600, 'subsample': 0.5, 'colsample_bytree': 0.9000000000000001, 'reg_lambda': 1.109805119363104, 'reg_alpha': 0.009095259146555868}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69909688 0.65795614 0.69185476 0.69394747]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:48,526] Trial 97 finished with value: 0.6994754144605503 and parameters: {'max_depth': 8, 'learning_rate': 0.06179137262174368, 'n_estimators': 600, 'subsample': 0.2, 'colsample_bytree': 0.6000000000000001, 'reg_lambda': 2.389187749787576, 'reg_alpha': 0.0034268916384208314}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7044335  0.66480447 0.69726562 0.69947541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:49,622] Trial 98 finished with value: 0.6969962459855914 and parameters: {'max_depth': 7, 'learning_rate': 0.04514443761299736, 'n_estimators': 900, 'subsample': 0.4, 'colsample_bytree': 0.8, 'reg_lambda': 7.919032493539401, 'reg_alpha': 0.005224794246585099}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70238095 0.66042155 0.69732938 0.69699625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-30 16:36:50,333] Trial 99 finished with value: 0.6965486936897839 and parameters: {'max_depth': 5, 'learning_rate': 0.03127513623855104, 'n_estimators': 700, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.7, 'reg_lambda': 4.1588797644185584, 'reg_alpha': 0.013310898396894963}. Best is trial 71 with value: 0.7097623361687353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70279146 0.65654649 0.70325203 0.69654869]\n",
      "[1]\tvalid_0's binary_logloss: 0.685002\n",
      "[2]\tvalid_0's binary_logloss: 0.680579\n",
      "[3]\tvalid_0's binary_logloss: 0.676365\n",
      "[4]\tvalid_0's binary_logloss: 0.671677\n",
      "[5]\tvalid_0's binary_logloss: 0.667223\n",
      "[6]\tvalid_0's binary_logloss: 0.663739\n",
      "[7]\tvalid_0's binary_logloss: 0.660104\n",
      "[8]\tvalid_0's binary_logloss: 0.656386\n",
      "[9]\tvalid_0's binary_logloss: 0.653585\n",
      "[10]\tvalid_0's binary_logloss: 0.650407\n",
      "[11]\tvalid_0's binary_logloss: 0.647244\n",
      "[12]\tvalid_0's binary_logloss: 0.644834\n",
      "[13]\tvalid_0's binary_logloss: 0.642224\n",
      "[14]\tvalid_0's binary_logloss: 0.639548\n",
      "[15]\tvalid_0's binary_logloss: 0.63699\n",
      "[16]\tvalid_0's binary_logloss: 0.63506\n",
      "[17]\tvalid_0's binary_logloss: 0.632696\n",
      "[18]\tvalid_0's binary_logloss: 0.63055\n",
      "[19]\tvalid_0's binary_logloss: 0.628944\n",
      "[20]\tvalid_0's binary_logloss: 0.626891\n",
      "[21]\tvalid_0's binary_logloss: 0.624873\n",
      "[22]\tvalid_0's binary_logloss: 0.623557\n",
      "[23]\tvalid_0's binary_logloss: 0.621813\n",
      "[24]\tvalid_0's binary_logloss: 0.620124\n",
      "[25]\tvalid_0's binary_logloss: 0.618549\n",
      "[26]\tvalid_0's binary_logloss: 0.616898\n",
      "[27]\tvalid_0's binary_logloss: 0.615881\n",
      "[28]\tvalid_0's binary_logloss: 0.614418\n",
      "[29]\tvalid_0's binary_logloss: 0.613021\n",
      "[30]\tvalid_0's binary_logloss: 0.611829\n",
      "[31]\tvalid_0's binary_logloss: 0.611029\n",
      "[32]\tvalid_0's binary_logloss: 0.609853\n",
      "[33]\tvalid_0's binary_logloss: 0.609145\n",
      "[34]\tvalid_0's binary_logloss: 0.608053\n",
      "[35]\tvalid_0's binary_logloss: 0.607014\n",
      "[36]\tvalid_0's binary_logloss: 0.605939\n",
      "[37]\tvalid_0's binary_logloss: 0.604943\n",
      "[38]\tvalid_0's binary_logloss: 0.604125\n",
      "[39]\tvalid_0's binary_logloss: 0.603274\n",
      "[40]\tvalid_0's binary_logloss: 0.602242\n",
      "[41]\tvalid_0's binary_logloss: 0.601612\n",
      "[42]\tvalid_0's binary_logloss: 0.600808\n",
      "[43]\tvalid_0's binary_logloss: 0.600122\n",
      "[44]\tvalid_0's binary_logloss: 0.599337\n",
      "[45]\tvalid_0's binary_logloss: 0.598685\n",
      "[46]\tvalid_0's binary_logloss: 0.597958\n",
      "[47]\tvalid_0's binary_logloss: 0.597341\n",
      "[48]\tvalid_0's binary_logloss: 0.597085\n",
      "[49]\tvalid_0's binary_logloss: 0.596648\n",
      "[50]\tvalid_0's binary_logloss: 0.59601\n",
      "[51]\tvalid_0's binary_logloss: 0.595541\n",
      "[52]\tvalid_0's binary_logloss: 0.595103\n",
      "[53]\tvalid_0's binary_logloss: 0.594416\n",
      "[54]\tvalid_0's binary_logloss: 0.593885\n",
      "[55]\tvalid_0's binary_logloss: 0.593517\n",
      "[56]\tvalid_0's binary_logloss: 0.593353\n",
      "[57]\tvalid_0's binary_logloss: 0.59293\n",
      "[58]\tvalid_0's binary_logloss: 0.592562\n",
      "[59]\tvalid_0's binary_logloss: 0.592325\n",
      "[60]\tvalid_0's binary_logloss: 0.592107\n",
      "[61]\tvalid_0's binary_logloss: 0.591912\n",
      "[62]\tvalid_0's binary_logloss: 0.591511\n",
      "[63]\tvalid_0's binary_logloss: 0.59088\n",
      "[64]\tvalid_0's binary_logloss: 0.590557\n",
      "[65]\tvalid_0's binary_logloss: 0.590268\n",
      "[66]\tvalid_0's binary_logloss: 0.589737\n",
      "[67]\tvalid_0's binary_logloss: 0.589706\n",
      "[68]\tvalid_0's binary_logloss: 0.589299\n",
      "[69]\tvalid_0's binary_logloss: 0.58915\n",
      "[70]\tvalid_0's binary_logloss: 0.589015\n",
      "[71]\tvalid_0's binary_logloss: 0.588924\n",
      "[72]\tvalid_0's binary_logloss: 0.588815\n",
      "[73]\tvalid_0's binary_logloss: 0.588733\n",
      "[74]\tvalid_0's binary_logloss: 0.588281\n",
      "[75]\tvalid_0's binary_logloss: 0.588163\n",
      "[76]\tvalid_0's binary_logloss: 0.58763\n",
      "[77]\tvalid_0's binary_logloss: 0.587576\n",
      "[78]\tvalid_0's binary_logloss: 0.587177\n",
      "[79]\tvalid_0's binary_logloss: 0.586958\n",
      "[80]\tvalid_0's binary_logloss: 0.586665\n",
      "[81]\tvalid_0's binary_logloss: 0.586614\n",
      "[82]\tvalid_0's binary_logloss: 0.586518\n",
      "[83]\tvalid_0's binary_logloss: 0.586478\n",
      "[84]\tvalid_0's binary_logloss: 0.586147\n",
      "[85]\tvalid_0's binary_logloss: 0.586082\n",
      "[86]\tvalid_0's binary_logloss: 0.586023\n",
      "[87]\tvalid_0's binary_logloss: 0.585979\n",
      "[88]\tvalid_0's binary_logloss: 0.585673\n",
      "[89]\tvalid_0's binary_logloss: 0.585514\n",
      "[90]\tvalid_0's binary_logloss: 0.585343\n",
      "[91]\tvalid_0's binary_logloss: 0.585252\n",
      "[92]\tvalid_0's binary_logloss: 0.584955\n",
      "[93]\tvalid_0's binary_logloss: 0.584689\n",
      "[94]\tvalid_0's binary_logloss: 0.58465\n",
      "[95]\tvalid_0's binary_logloss: 0.584321\n",
      "[96]\tvalid_0's binary_logloss: 0.584186\n",
      "[97]\tvalid_0's binary_logloss: 0.584154\n",
      "[98]\tvalid_0's binary_logloss: 0.583951\n",
      "[99]\tvalid_0's binary_logloss: 0.583906\n",
      "[100]\tvalid_0's binary_logloss: 0.58372\n",
      "[101]\tvalid_0's binary_logloss: 0.583679\n",
      "[102]\tvalid_0's binary_logloss: 0.583373\n",
      "[103]\tvalid_0's binary_logloss: 0.583361\n",
      "[104]\tvalid_0's binary_logloss: 0.583369\n",
      "[105]\tvalid_0's binary_logloss: 0.583158\n",
      "[106]\tvalid_0's binary_logloss: 0.583137\n",
      "[107]\tvalid_0's binary_logloss: 0.582998\n",
      "[108]\tvalid_0's binary_logloss: 0.582943\n",
      "[109]\tvalid_0's binary_logloss: 0.582907\n",
      "[110]\tvalid_0's binary_logloss: 0.582646\n",
      "[111]\tvalid_0's binary_logloss: 0.582528\n",
      "[112]\tvalid_0's binary_logloss: 0.582468\n",
      "[113]\tvalid_0's binary_logloss: 0.582476\n",
      "[114]\tvalid_0's binary_logloss: 0.582388\n",
      "[115]\tvalid_0's binary_logloss: 0.582361\n",
      "[116]\tvalid_0's binary_logloss: 0.582301\n",
      "[117]\tvalid_0's binary_logloss: 0.582321\n",
      "[118]\tvalid_0's binary_logloss: 0.582315\n",
      "[119]\tvalid_0's binary_logloss: 0.582312\n",
      "[120]\tvalid_0's binary_logloss: 0.582102\n",
      "[121]\tvalid_0's binary_logloss: 0.582166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiera\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122]\tvalid_0's binary_logloss: 0.582086\n",
      "[123]\tvalid_0's binary_logloss: 0.582069\n",
      "[124]\tvalid_0's binary_logloss: 0.582048\n",
      "[125]\tvalid_0's binary_logloss: 0.582089\n",
      "[126]\tvalid_0's binary_logloss: 0.582056\n",
      "[127]\tvalid_0's binary_logloss: 0.582099\n",
      "[128]\tvalid_0's binary_logloss: 0.582095\n",
      "[129]\tvalid_0's binary_logloss: 0.58209\n",
      "[130]\tvalid_0's binary_logloss: 0.582048\n",
      "[131]\tvalid_0's binary_logloss: 0.581884\n",
      "[132]\tvalid_0's binary_logloss: 0.581853\n",
      "[133]\tvalid_0's binary_logloss: 0.581813\n",
      "[134]\tvalid_0's binary_logloss: 0.581809\n",
      "[135]\tvalid_0's binary_logloss: 0.58162\n",
      "[136]\tvalid_0's binary_logloss: 0.581579\n",
      "[137]\tvalid_0's binary_logloss: 0.581597\n",
      "[138]\tvalid_0's binary_logloss: 0.581305\n",
      "[139]\tvalid_0's binary_logloss: 0.581463\n",
      "[140]\tvalid_0's binary_logloss: 0.581438\n",
      "[141]\tvalid_0's binary_logloss: 0.581293\n",
      "[142]\tvalid_0's binary_logloss: 0.581236\n",
      "[143]\tvalid_0's binary_logloss: 0.58128\n",
      "[144]\tvalid_0's binary_logloss: 0.581267\n",
      "[145]\tvalid_0's binary_logloss: 0.580992\n",
      "[146]\tvalid_0's binary_logloss: 0.58072\n",
      "[147]\tvalid_0's binary_logloss: 0.580648\n",
      "[148]\tvalid_0's binary_logloss: 0.580645\n",
      "[149]\tvalid_0's binary_logloss: 0.580701\n",
      "[150]\tvalid_0's binary_logloss: 0.580642\n",
      "[151]\tvalid_0's binary_logloss: 0.580523\n",
      "[152]\tvalid_0's binary_logloss: 0.580272\n",
      "[153]\tvalid_0's binary_logloss: 0.580279\n",
      "[154]\tvalid_0's binary_logloss: 0.580331\n",
      "[155]\tvalid_0's binary_logloss: 0.58009\n",
      "[156]\tvalid_0's binary_logloss: 0.58012\n",
      "[157]\tvalid_0's binary_logloss: 0.580072\n",
      "[158]\tvalid_0's binary_logloss: 0.579958\n",
      "[159]\tvalid_0's binary_logloss: 0.579739\n",
      "[160]\tvalid_0's binary_logloss: 0.579715\n",
      "[161]\tvalid_0's binary_logloss: 0.579709\n",
      "[162]\tvalid_0's binary_logloss: 0.579667\n",
      "[163]\tvalid_0's binary_logloss: 0.579684\n",
      "[164]\tvalid_0's binary_logloss: 0.579696\n",
      "[165]\tvalid_0's binary_logloss: 0.579663\n",
      "[166]\tvalid_0's binary_logloss: 0.57956\n",
      "[167]\tvalid_0's binary_logloss: 0.579567\n",
      "[168]\tvalid_0's binary_logloss: 0.579543\n",
      "[169]\tvalid_0's binary_logloss: 0.579574\n",
      "[170]\tvalid_0's binary_logloss: 0.57958\n",
      "[171]\tvalid_0's binary_logloss: 0.579581\n",
      "[172]\tvalid_0's binary_logloss: 0.579398\n",
      "[173]\tvalid_0's binary_logloss: 0.579431\n",
      "[174]\tvalid_0's binary_logloss: 0.579431\n",
      "[175]\tvalid_0's binary_logloss: 0.579369\n",
      "[176]\tvalid_0's binary_logloss: 0.579336\n",
      "[177]\tvalid_0's binary_logloss: 0.57935\n",
      "[178]\tvalid_0's binary_logloss: 0.579336\n",
      "[179]\tvalid_0's binary_logloss: 0.579131\n",
      "[180]\tvalid_0's binary_logloss: 0.578923\n",
      "[181]\tvalid_0's binary_logloss: 0.57868\n",
      "[182]\tvalid_0's binary_logloss: 0.578472\n",
      "[183]\tvalid_0's binary_logloss: 0.578484\n",
      "[184]\tvalid_0's binary_logloss: 0.578374\n",
      "[185]\tvalid_0's binary_logloss: 0.578307\n",
      "[186]\tvalid_0's binary_logloss: 0.578333\n",
      "[187]\tvalid_0's binary_logloss: 0.578114\n",
      "[188]\tvalid_0's binary_logloss: 0.577924\n",
      "[189]\tvalid_0's binary_logloss: 0.577775\n",
      "[190]\tvalid_0's binary_logloss: 0.577572\n",
      "[191]\tvalid_0's binary_logloss: 0.577563\n",
      "[192]\tvalid_0's binary_logloss: 0.577552\n",
      "[193]\tvalid_0's binary_logloss: 0.577542\n",
      "[194]\tvalid_0's binary_logloss: 0.577499\n",
      "[195]\tvalid_0's binary_logloss: 0.577531\n",
      "[196]\tvalid_0's binary_logloss: 0.577511\n",
      "[197]\tvalid_0's binary_logloss: 0.577415\n",
      "[198]\tvalid_0's binary_logloss: 0.577411\n",
      "[199]\tvalid_0's binary_logloss: 0.577409\n",
      "[200]\tvalid_0's binary_logloss: 0.577385\n",
      "[201]\tvalid_0's binary_logloss: 0.577353\n",
      "[202]\tvalid_0's binary_logloss: 0.577145\n",
      "[203]\tvalid_0's binary_logloss: 0.577131\n",
      "[204]\tvalid_0's binary_logloss: 0.57712\n",
      "[205]\tvalid_0's binary_logloss: 0.577173\n",
      "[206]\tvalid_0's binary_logloss: 0.577166\n",
      "[207]\tvalid_0's binary_logloss: 0.576962\n",
      "[208]\tvalid_0's binary_logloss: 0.57701\n",
      "[209]\tvalid_0's binary_logloss: 0.577043\n",
      "[210]\tvalid_0's binary_logloss: 0.57691\n",
      "[211]\tvalid_0's binary_logloss: 0.57673\n",
      "[212]\tvalid_0's binary_logloss: 0.576699\n",
      "[213]\tvalid_0's binary_logloss: 0.576688\n",
      "[214]\tvalid_0's binary_logloss: 0.576445\n",
      "[215]\tvalid_0's binary_logloss: 0.576296\n",
      "[216]\tvalid_0's binary_logloss: 0.576111\n",
      "[217]\tvalid_0's binary_logloss: 0.575942\n",
      "[218]\tvalid_0's binary_logloss: 0.575967\n",
      "[219]\tvalid_0's binary_logloss: 0.575782\n",
      "[220]\tvalid_0's binary_logloss: 0.575581\n",
      "[221]\tvalid_0's binary_logloss: 0.575481\n",
      "[222]\tvalid_0's binary_logloss: 0.575489\n",
      "[223]\tvalid_0's binary_logloss: 0.575449\n",
      "[224]\tvalid_0's binary_logloss: 0.575435\n",
      "[225]\tvalid_0's binary_logloss: 0.57531\n",
      "[226]\tvalid_0's binary_logloss: 0.575128\n",
      "[227]\tvalid_0's binary_logloss: 0.575095\n",
      "[228]\tvalid_0's binary_logloss: 0.574928\n",
      "[229]\tvalid_0's binary_logloss: 0.574931\n",
      "[230]\tvalid_0's binary_logloss: 0.574967\n",
      "[231]\tvalid_0's binary_logloss: 0.574995\n",
      "[232]\tvalid_0's binary_logloss: 0.574986\n",
      "[233]\tvalid_0's binary_logloss: 0.574957\n",
      "[234]\tvalid_0's binary_logloss: 0.574954\n",
      "[235]\tvalid_0's binary_logloss: 0.574949\n",
      "[236]\tvalid_0's binary_logloss: 0.57481\n",
      "[237]\tvalid_0's binary_logloss: 0.574828\n",
      "[238]\tvalid_0's binary_logloss: 0.574869\n",
      "[239]\tvalid_0's binary_logloss: 0.5749\n",
      "[240]\tvalid_0's binary_logloss: 0.574854\n",
      "[241]\tvalid_0's binary_logloss: 0.574692\n",
      "[242]\tvalid_0's binary_logloss: 0.574535\n",
      "[243]\tvalid_0's binary_logloss: 0.574538\n",
      "[244]\tvalid_0's binary_logloss: 0.57443\n",
      "[245]\tvalid_0's binary_logloss: 0.574436\n",
      "[246]\tvalid_0's binary_logloss: 0.574406\n",
      "[247]\tvalid_0's binary_logloss: 0.574456\n",
      "[248]\tvalid_0's binary_logloss: 0.574339\n",
      "[249]\tvalid_0's binary_logloss: 0.574343\n",
      "[250]\tvalid_0's binary_logloss: 0.574202\n",
      "[251]\tvalid_0's binary_logloss: 0.574186\n",
      "[252]\tvalid_0's binary_logloss: 0.57417\n",
      "[253]\tvalid_0's binary_logloss: 0.574217\n",
      "[254]\tvalid_0's binary_logloss: 0.574165\n",
      "[255]\tvalid_0's binary_logloss: 0.574189\n",
      "[256]\tvalid_0's binary_logloss: 0.57424\n",
      "[257]\tvalid_0's binary_logloss: 0.574181\n",
      "[258]\tvalid_0's binary_logloss: 0.573956\n",
      "[259]\tvalid_0's binary_logloss: 0.573931\n",
      "[260]\tvalid_0's binary_logloss: 0.57379\n",
      "[261]\tvalid_0's binary_logloss: 0.573789\n",
      "[262]\tvalid_0's binary_logloss: 0.573762\n",
      "[263]\tvalid_0's binary_logloss: 0.57378\n",
      "[264]\tvalid_0's binary_logloss: 0.573764\n",
      "[265]\tvalid_0's binary_logloss: 0.573653\n",
      "[266]\tvalid_0's binary_logloss: 0.573459\n",
      "[267]\tvalid_0's binary_logloss: 0.573415\n",
      "[268]\tvalid_0's binary_logloss: 0.57345\n",
      "[269]\tvalid_0's binary_logloss: 0.573528\n",
      "[270]\tvalid_0's binary_logloss: 0.573399\n",
      "[271]\tvalid_0's binary_logloss: 0.573386\n",
      "[272]\tvalid_0's binary_logloss: 0.573421\n",
      "[273]\tvalid_0's binary_logloss: 0.573454\n",
      "[274]\tvalid_0's binary_logloss: 0.573379\n",
      "[275]\tvalid_0's binary_logloss: 0.573376\n",
      "[276]\tvalid_0's binary_logloss: 0.573285\n",
      "[277]\tvalid_0's binary_logloss: 0.573134\n",
      "[278]\tvalid_0's binary_logloss: 0.5731\n",
      "[279]\tvalid_0's binary_logloss: 0.572986\n",
      "[280]\tvalid_0's binary_logloss: 0.573028\n",
      "[281]\tvalid_0's binary_logloss: 0.573077\n",
      "[282]\tvalid_0's binary_logloss: 0.572879\n",
      "[283]\tvalid_0's binary_logloss: 0.572864\n",
      "[284]\tvalid_0's binary_logloss: 0.572921\n",
      "[285]\tvalid_0's binary_logloss: 0.572974\n",
      "[286]\tvalid_0's binary_logloss: 0.572816\n",
      "[287]\tvalid_0's binary_logloss: 0.572841\n",
      "[288]\tvalid_0's binary_logloss: 0.572668\n",
      "[289]\tvalid_0's binary_logloss: 0.572567\n",
      "[290]\tvalid_0's binary_logloss: 0.572575\n",
      "[291]\tvalid_0's binary_logloss: 0.572525\n",
      "[292]\tvalid_0's binary_logloss: 0.572501\n",
      "[293]\tvalid_0's binary_logloss: 0.572509\n",
      "[294]\tvalid_0's binary_logloss: 0.572384\n",
      "[295]\tvalid_0's binary_logloss: 0.572279\n",
      "[296]\tvalid_0's binary_logloss: 0.572345\n",
      "[297]\tvalid_0's binary_logloss: 0.572174\n",
      "[298]\tvalid_0's binary_logloss: 0.572064\n",
      "[299]\tvalid_0's binary_logloss: 0.572005\n",
      "[300]\tvalid_0's binary_logloss: 0.571864\n",
      "[301]\tvalid_0's binary_logloss: 0.571766\n",
      "[302]\tvalid_0's binary_logloss: 0.571732\n",
      "[303]\tvalid_0's binary_logloss: 0.571739\n",
      "[304]\tvalid_0's binary_logloss: 0.571738\n",
      "[305]\tvalid_0's binary_logloss: 0.571739\n",
      "[306]\tvalid_0's binary_logloss: 0.571758\n",
      "[307]\tvalid_0's binary_logloss: 0.571735\n",
      "[308]\tvalid_0's binary_logloss: 0.571744\n",
      "[309]\tvalid_0's binary_logloss: 0.571777\n",
      "[310]\tvalid_0's binary_logloss: 0.57176\n",
      "[311]\tvalid_0's binary_logloss: 0.571767\n",
      "[312]\tvalid_0's binary_logloss: 0.571766\n",
      "[313]\tvalid_0's binary_logloss: 0.57176\n",
      "[314]\tvalid_0's binary_logloss: 0.571627\n",
      "[315]\tvalid_0's binary_logloss: 0.571672\n",
      "[316]\tvalid_0's binary_logloss: 0.571741\n",
      "[317]\tvalid_0's binary_logloss: 0.571792\n",
      "[318]\tvalid_0's binary_logloss: 0.571817\n",
      "[319]\tvalid_0's binary_logloss: 0.571842\n",
      "[320]\tvalid_0's binary_logloss: 0.57185\n",
      "[321]\tvalid_0's binary_logloss: 0.571741\n",
      "[322]\tvalid_0's binary_logloss: 0.571721\n",
      "[323]\tvalid_0's binary_logloss: 0.571714\n",
      "[324]\tvalid_0's binary_logloss: 0.571645\n",
      "[325]\tvalid_0's binary_logloss: 0.571654\n",
      "[326]\tvalid_0's binary_logloss: 0.571608\n",
      "[327]\tvalid_0's binary_logloss: 0.571473\n",
      "[328]\tvalid_0's binary_logloss: 0.571481\n",
      "[329]\tvalid_0's binary_logloss: 0.571333\n",
      "[330]\tvalid_0's binary_logloss: 0.571281\n",
      "[331]\tvalid_0's binary_logloss: 0.571281\n",
      "[332]\tvalid_0's binary_logloss: 0.571204\n",
      "[333]\tvalid_0's binary_logloss: 0.571091\n",
      "[334]\tvalid_0's binary_logloss: 0.571125\n",
      "[335]\tvalid_0's binary_logloss: 0.571128\n",
      "[336]\tvalid_0's binary_logloss: 0.571016\n",
      "[337]\tvalid_0's binary_logloss: 0.570999\n",
      "[338]\tvalid_0's binary_logloss: 0.571038\n",
      "[339]\tvalid_0's binary_logloss: 0.571036\n",
      "[340]\tvalid_0's binary_logloss: 0.571065\n",
      "[341]\tvalid_0's binary_logloss: 0.570944\n",
      "[342]\tvalid_0's binary_logloss: 0.570913\n",
      "[343]\tvalid_0's binary_logloss: 0.570927\n",
      "[344]\tvalid_0's binary_logloss: 0.570816\n",
      "[345]\tvalid_0's binary_logloss: 0.570707\n",
      "[346]\tvalid_0's binary_logloss: 0.570651\n",
      "[347]\tvalid_0's binary_logloss: 0.570583\n",
      "[348]\tvalid_0's binary_logloss: 0.570539\n",
      "[349]\tvalid_0's binary_logloss: 0.570512\n",
      "[350]\tvalid_0's binary_logloss: 0.57055\n",
      "[351]\tvalid_0's binary_logloss: 0.57047\n",
      "[352]\tvalid_0's binary_logloss: 0.570503\n",
      "[353]\tvalid_0's binary_logloss: 0.570441\n",
      "[354]\tvalid_0's binary_logloss: 0.570469\n",
      "[355]\tvalid_0's binary_logloss: 0.570475\n",
      "[356]\tvalid_0's binary_logloss: 0.570451\n",
      "[357]\tvalid_0's binary_logloss: 0.570423\n",
      "[358]\tvalid_0's binary_logloss: 0.570443\n",
      "[359]\tvalid_0's binary_logloss: 0.570459\n",
      "[360]\tvalid_0's binary_logloss: 0.570458\n",
      "[361]\tvalid_0's binary_logloss: 0.570514\n",
      "[362]\tvalid_0's binary_logloss: 0.570527\n",
      "[363]\tvalid_0's binary_logloss: 0.570485\n",
      "[364]\tvalid_0's binary_logloss: 0.570482\n",
      "[365]\tvalid_0's binary_logloss: 0.570477\n",
      "[366]\tvalid_0's binary_logloss: 0.570504\n",
      "[367]\tvalid_0's binary_logloss: 0.570526\n",
      "[368]\tvalid_0's binary_logloss: 0.570552\n",
      "[369]\tvalid_0's binary_logloss: 0.570548\n",
      "[370]\tvalid_0's binary_logloss: 0.570582\n",
      "[371]\tvalid_0's binary_logloss: 0.570595\n",
      "[372]\tvalid_0's binary_logloss: 0.570563\n",
      "[373]\tvalid_0's binary_logloss: 0.57062\n",
      "[374]\tvalid_0's binary_logloss: 0.570635\n",
      "[375]\tvalid_0's binary_logloss: 0.570619\n",
      "[376]\tvalid_0's binary_logloss: 0.570655\n",
      "[377]\tvalid_0's binary_logloss: 0.570689\n",
      "[378]\tvalid_0's binary_logloss: 0.570745\n",
      "[379]\tvalid_0's binary_logloss: 0.570792\n",
      "[380]\tvalid_0's binary_logloss: 0.570813\n",
      "[381]\tvalid_0's binary_logloss: 0.570791\n",
      "[382]\tvalid_0's binary_logloss: 0.57078\n",
      "[383]\tvalid_0's binary_logloss: 0.570782\n",
      "[384]\tvalid_0's binary_logloss: 0.570676\n",
      "[385]\tvalid_0's binary_logloss: 0.570585\n",
      "[386]\tvalid_0's binary_logloss: 0.570624\n",
      "[387]\tvalid_0's binary_logloss: 0.570657\n",
      "[388]\tvalid_0's binary_logloss: 0.570669\n",
      "[389]\tvalid_0's binary_logloss: 0.570715\n",
      "[390]\tvalid_0's binary_logloss: 0.570719\n",
      "[391]\tvalid_0's binary_logloss: 0.570685\n",
      "[392]\tvalid_0's binary_logloss: 0.570657\n",
      "[393]\tvalid_0's binary_logloss: 0.570622\n",
      "[394]\tvalid_0's binary_logloss: 0.570664\n",
      "[395]\tvalid_0's binary_logloss: 0.570622\n",
      "[396]\tvalid_0's binary_logloss: 0.570669\n",
      "[397]\tvalid_0's binary_logloss: 0.570643\n",
      "[398]\tvalid_0's binary_logloss: 0.570684\n",
      "[399]\tvalid_0's binary_logloss: 0.570703\n",
      "[400]\tvalid_0's binary_logloss: 0.57069\n",
      "[401]\tvalid_0's binary_logloss: 0.5707\n",
      "[402]\tvalid_0's binary_logloss: 0.570712\n",
      "[403]\tvalid_0's binary_logloss: 0.570674\n",
      "[404]\tvalid_0's binary_logloss: 0.570676\n",
      "[405]\tvalid_0's binary_logloss: 0.570718\n",
      "[406]\tvalid_0's binary_logloss: 0.570711\n",
      "[407]\tvalid_0's binary_logloss: 0.570743\n",
      "[408]\tvalid_0's binary_logloss: 0.570759\n",
      "[409]\tvalid_0's binary_logloss: 0.570763\n",
      "[410]\tvalid_0's binary_logloss: 0.570781\n",
      "[411]\tvalid_0's binary_logloss: 0.570785\n",
      "[412]\tvalid_0's binary_logloss: 0.57079\n",
      "[413]\tvalid_0's binary_logloss: 0.570806\n",
      "[414]\tvalid_0's binary_logloss: 0.570831\n",
      "[415]\tvalid_0's binary_logloss: 0.570832\n",
      "[416]\tvalid_0's binary_logloss: 0.570798\n",
      "[417]\tvalid_0's binary_logloss: 0.570838\n",
      "[418]\tvalid_0's binary_logloss: 0.570847\n",
      "[419]\tvalid_0's binary_logloss: 0.570868\n",
      "[420]\tvalid_0's binary_logloss: 0.570878\n",
      "[421]\tvalid_0's binary_logloss: 0.570867\n",
      "[422]\tvalid_0's binary_logloss: 0.570864\n",
      "[423]\tvalid_0's binary_logloss: 0.570869\n",
      "[424]\tvalid_0's binary_logloss: 0.57086\n",
      "[425]\tvalid_0's binary_logloss: 0.570853\n",
      "[426]\tvalid_0's binary_logloss: 0.570861\n",
      "[427]\tvalid_0's binary_logloss: 0.570879\n",
      "[428]\tvalid_0's binary_logloss: 0.570798\n",
      "[429]\tvalid_0's binary_logloss: 0.570782\n",
      "[430]\tvalid_0's binary_logloss: 0.570805\n",
      "[431]\tvalid_0's binary_logloss: 0.570748\n",
      "[432]\tvalid_0's binary_logloss: 0.570633\n",
      "[433]\tvalid_0's binary_logloss: 0.570643\n",
      "[434]\tvalid_0's binary_logloss: 0.570672\n",
      "[435]\tvalid_0's binary_logloss: 0.570654\n",
      "[436]\tvalid_0's binary_logloss: 0.570669\n",
      "[437]\tvalid_0's binary_logloss: 0.570665\n",
      "[438]\tvalid_0's binary_logloss: 0.57065\n",
      "[439]\tvalid_0's binary_logloss: 0.570653\n",
      "[440]\tvalid_0's binary_logloss: 0.570518\n",
      "[441]\tvalid_0's binary_logloss: 0.570401\n",
      "[442]\tvalid_0's binary_logloss: 0.570442\n",
      "[443]\tvalid_0's binary_logloss: 0.570369\n",
      "[444]\tvalid_0's binary_logloss: 0.570271\n",
      "[445]\tvalid_0's binary_logloss: 0.570334\n",
      "[446]\tvalid_0's binary_logloss: 0.570283\n",
      "[447]\tvalid_0's binary_logloss: 0.570199\n",
      "[448]\tvalid_0's binary_logloss: 0.570239\n",
      "[449]\tvalid_0's binary_logloss: 0.570242\n",
      "[450]\tvalid_0's binary_logloss: 0.570244\n",
      "[451]\tvalid_0's binary_logloss: 0.570285\n",
      "[452]\tvalid_0's binary_logloss: 0.570172\n",
      "[453]\tvalid_0's binary_logloss: 0.570102\n",
      "[454]\tvalid_0's binary_logloss: 0.570065\n",
      "[455]\tvalid_0's binary_logloss: 0.570029\n",
      "[456]\tvalid_0's binary_logloss: 0.570089\n",
      "[457]\tvalid_0's binary_logloss: 0.569955\n",
      "[458]\tvalid_0's binary_logloss: 0.569909\n",
      "[459]\tvalid_0's binary_logloss: 0.569957\n",
      "[460]\tvalid_0's binary_logloss: 0.569972\n",
      "[461]\tvalid_0's binary_logloss: 0.569985\n",
      "[462]\tvalid_0's binary_logloss: 0.569907\n",
      "[463]\tvalid_0's binary_logloss: 0.569928\n",
      "[464]\tvalid_0's binary_logloss: 0.56993\n",
      "[465]\tvalid_0's binary_logloss: 0.569989\n",
      "[466]\tvalid_0's binary_logloss: 0.569905\n",
      "[467]\tvalid_0's binary_logloss: 0.569838\n",
      "[468]\tvalid_0's binary_logloss: 0.569779\n",
      "[469]\tvalid_0's binary_logloss: 0.569775\n",
      "[470]\tvalid_0's binary_logloss: 0.569758\n",
      "[471]\tvalid_0's binary_logloss: 0.569799\n",
      "[472]\tvalid_0's binary_logloss: 0.569803\n",
      "[473]\tvalid_0's binary_logloss: 0.569846\n",
      "[474]\tvalid_0's binary_logloss: 0.569863\n",
      "[475]\tvalid_0's binary_logloss: 0.569872\n",
      "[476]\tvalid_0's binary_logloss: 0.569929\n",
      "[477]\tvalid_0's binary_logloss: 0.569912\n",
      "[478]\tvalid_0's binary_logloss: 0.569906\n",
      "[479]\tvalid_0's binary_logloss: 0.569964\n",
      "[480]\tvalid_0's binary_logloss: 0.569944\n",
      "[481]\tvalid_0's binary_logloss: 0.569949\n",
      "[482]\tvalid_0's binary_logloss: 0.569929\n",
      "[483]\tvalid_0's binary_logloss: 0.569931\n",
      "[484]\tvalid_0's binary_logloss: 0.569923\n",
      "[485]\tvalid_0's binary_logloss: 0.569939\n",
      "[486]\tvalid_0's binary_logloss: 0.569933\n",
      "[487]\tvalid_0's binary_logloss: 0.569954\n",
      "[488]\tvalid_0's binary_logloss: 0.569979\n",
      "[489]\tvalid_0's binary_logloss: 0.570018\n",
      "[490]\tvalid_0's binary_logloss: 0.569996\n",
      "[491]\tvalid_0's binary_logloss: 0.569901\n",
      "[492]\tvalid_0's binary_logloss: 0.569874\n",
      "[493]\tvalid_0's binary_logloss: 0.569865\n",
      "[494]\tvalid_0's binary_logloss: 0.569874\n",
      "[495]\tvalid_0's binary_logloss: 0.569841\n",
      "[496]\tvalid_0's binary_logloss: 0.569861\n",
      "[497]\tvalid_0's binary_logloss: 0.56974\n",
      "[498]\tvalid_0's binary_logloss: 0.569656\n",
      "[499]\tvalid_0's binary_logloss: 0.56966\n",
      "[500]\tvalid_0's binary_logloss: 0.569609\n",
      "[501]\tvalid_0's binary_logloss: 0.56953\n",
      "[502]\tvalid_0's binary_logloss: 0.569434\n",
      "[503]\tvalid_0's binary_logloss: 0.569467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[504]\tvalid_0's binary_logloss: 0.569398\n",
      "[505]\tvalid_0's binary_logloss: 0.569414\n",
      "[506]\tvalid_0's binary_logloss: 0.569378\n",
      "[507]\tvalid_0's binary_logloss: 0.569234\n",
      "[508]\tvalid_0's binary_logloss: 0.569145\n",
      "[509]\tvalid_0's binary_logloss: 0.569133\n",
      "[510]\tvalid_0's binary_logloss: 0.5691\n",
      "[511]\tvalid_0's binary_logloss: 0.569032\n",
      "[512]\tvalid_0's binary_logloss: 0.569002\n",
      "[513]\tvalid_0's binary_logloss: 0.568963\n",
      "[514]\tvalid_0's binary_logloss: 0.56891\n",
      "[515]\tvalid_0's binary_logloss: 0.5689\n",
      "[516]\tvalid_0's binary_logloss: 0.568888\n",
      "[517]\tvalid_0's binary_logloss: 0.568911\n",
      "[518]\tvalid_0's binary_logloss: 0.568863\n",
      "[519]\tvalid_0's binary_logloss: 0.568844\n",
      "[520]\tvalid_0's binary_logloss: 0.568792\n",
      "[521]\tvalid_0's binary_logloss: 0.568807\n",
      "[522]\tvalid_0's binary_logloss: 0.568813\n",
      "[523]\tvalid_0's binary_logloss: 0.568832\n",
      "[524]\tvalid_0's binary_logloss: 0.568793\n",
      "[525]\tvalid_0's binary_logloss: 0.568768\n",
      "[526]\tvalid_0's binary_logloss: 0.568755\n",
      "[527]\tvalid_0's binary_logloss: 0.568735\n",
      "[528]\tvalid_0's binary_logloss: 0.568731\n",
      "[529]\tvalid_0's binary_logloss: 0.568686\n",
      "[530]\tvalid_0's binary_logloss: 0.568651\n",
      "[531]\tvalid_0's binary_logloss: 0.568638\n",
      "[532]\tvalid_0's binary_logloss: 0.568635\n",
      "[533]\tvalid_0's binary_logloss: 0.568696\n",
      "[534]\tvalid_0's binary_logloss: 0.568679\n",
      "[535]\tvalid_0's binary_logloss: 0.568644\n",
      "[536]\tvalid_0's binary_logloss: 0.56865\n",
      "[537]\tvalid_0's binary_logloss: 0.56865\n",
      "[538]\tvalid_0's binary_logloss: 0.568579\n",
      "[539]\tvalid_0's binary_logloss: 0.568556\n",
      "[540]\tvalid_0's binary_logloss: 0.568557\n",
      "[541]\tvalid_0's binary_logloss: 0.568528\n",
      "[542]\tvalid_0's binary_logloss: 0.568559\n",
      "[543]\tvalid_0's binary_logloss: 0.568489\n",
      "[544]\tvalid_0's binary_logloss: 0.568515\n",
      "[545]\tvalid_0's binary_logloss: 0.568475\n",
      "[546]\tvalid_0's binary_logloss: 0.568469\n",
      "[547]\tvalid_0's binary_logloss: 0.568442\n",
      "[548]\tvalid_0's binary_logloss: 0.568422\n",
      "[549]\tvalid_0's binary_logloss: 0.56841\n",
      "[550]\tvalid_0's binary_logloss: 0.568417\n",
      "[551]\tvalid_0's binary_logloss: 0.568381\n",
      "[552]\tvalid_0's binary_logloss: 0.568374\n",
      "[553]\tvalid_0's binary_logloss: 0.568374\n",
      "[554]\tvalid_0's binary_logloss: 0.5683\n",
      "[555]\tvalid_0's binary_logloss: 0.568272\n",
      "[556]\tvalid_0's binary_logloss: 0.568217\n",
      "[557]\tvalid_0's binary_logloss: 0.568129\n",
      "[558]\tvalid_0's binary_logloss: 0.568154\n",
      "[559]\tvalid_0's binary_logloss: 0.56816\n",
      "[560]\tvalid_0's binary_logloss: 0.568181\n",
      "[561]\tvalid_0's binary_logloss: 0.568161\n",
      "[562]\tvalid_0's binary_logloss: 0.568175\n",
      "[563]\tvalid_0's binary_logloss: 0.568172\n",
      "[564]\tvalid_0's binary_logloss: 0.568189\n",
      "[565]\tvalid_0's binary_logloss: 0.568216\n",
      "[566]\tvalid_0's binary_logloss: 0.568228\n",
      "[567]\tvalid_0's binary_logloss: 0.568204\n",
      "[568]\tvalid_0's binary_logloss: 0.568213\n",
      "[569]\tvalid_0's binary_logloss: 0.56821\n",
      "[570]\tvalid_0's binary_logloss: 0.568207\n",
      "[571]\tvalid_0's binary_logloss: 0.56822\n",
      "[572]\tvalid_0's binary_logloss: 0.568172\n",
      "[573]\tvalid_0's binary_logloss: 0.568097\n",
      "[574]\tvalid_0's binary_logloss: 0.568143\n",
      "[575]\tvalid_0's binary_logloss: 0.568149\n",
      "[576]\tvalid_0's binary_logloss: 0.568163\n",
      "[577]\tvalid_0's binary_logloss: 0.568173\n",
      "[578]\tvalid_0's binary_logloss: 0.568161\n",
      "[579]\tvalid_0's binary_logloss: 0.568108\n",
      "[580]\tvalid_0's binary_logloss: 0.568069\n",
      "[581]\tvalid_0's binary_logloss: 0.568073\n",
      "[582]\tvalid_0's binary_logloss: 0.568108\n",
      "[583]\tvalid_0's binary_logloss: 0.568135\n",
      "[584]\tvalid_0's binary_logloss: 0.568135\n",
      "[585]\tvalid_0's binary_logloss: 0.568113\n",
      "[586]\tvalid_0's binary_logloss: 0.568098\n",
      "[587]\tvalid_0's binary_logloss: 0.568116\n",
      "[588]\tvalid_0's binary_logloss: 0.568105\n",
      "[589]\tvalid_0's binary_logloss: 0.56811\n",
      "[590]\tvalid_0's binary_logloss: 0.568119\n",
      "[591]\tvalid_0's binary_logloss: 0.568114\n",
      "[592]\tvalid_0's binary_logloss: 0.568124\n",
      "[593]\tvalid_0's binary_logloss: 0.568145\n",
      "[594]\tvalid_0's binary_logloss: 0.568129\n",
      "[595]\tvalid_0's binary_logloss: 0.56815\n",
      "[596]\tvalid_0's binary_logloss: 0.568181\n",
      "[597]\tvalid_0's binary_logloss: 0.568201\n",
      "[598]\tvalid_0's binary_logloss: 0.568166\n",
      "[599]\tvalid_0's binary_logloss: 0.568104\n",
      "[600]\tvalid_0's binary_logloss: 0.568065\n",
      "Best Hyperparameters: {'max_depth': 6, 'learning_rate': 0.031881364207890645, 'n_estimators': 600, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_lambda': 6.550787086628024, 'reg_alpha': 0.004353727025251494}\n",
      "Test Accuracy: 0.7163382594417077\n",
      "Test F1 Score: 0.6701670644391409\n",
      "Test auc: 0.7735378602117873\n",
      "Test Precision Score: 0.7229660144181257\n"
     ]
    }
   ],
   "source": [
    "X_train = train[features]\n",
    "X_test = test[features]\n",
    "y_train = train['home_win']\n",
    "y_test = test['home_win']\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.2, 1.0, step=0.1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0, step=0.1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 10, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 10, log=True)\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    auc = np.mean(auc)\n",
    "    obj_vector = np.array([accuracy, f1, precision, auc])\n",
    "    print(obj_vector)\n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(directions=['maximize'])  \n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "\n",
    "best_params = study.best_params\n",
    "best_model = LGBMClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train, early_stopping_rounds=1000,\n",
    "                  eval_set=[(X_test, y_test)])\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_prob_test = best_model.predict_proba(X_test)[:, 1] \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "test_f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "test_roc_auc_score = roc_auc_score(y_test, y_prob_test)\n",
    "test_precision_score = precision_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test F1 Score:\", test_f1)\n",
    "print(\"Test auc:\", test_roc_auc_score)\n",
    "print(\"Test Precision Score:\", test_precision_score)\n",
    "\n",
    "model_filename = \"lgbm_home_win_with_odds.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0e49b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.25\n",
      "Confusion Matrix:\n",
      "[[ 488  824]\n",
      " [ 101 1023]]\n",
      "Precision: 0.5538711423930699\n",
      "Recall: 0.9101423487544484\n",
      "F1 Score: 0.6886570178391115\n",
      "-----------------------\n",
      "Threshold: 0.3\n",
      "Confusion Matrix:\n",
      "[[621 691]\n",
      " [157 967]]\n",
      "Precision: 0.583232810615199\n",
      "Recall: 0.8603202846975089\n",
      "F1 Score: 0.6951833213515457\n",
      "-----------------------\n",
      "Threshold: 0.35\n",
      "Confusion Matrix:\n",
      "[[751 561]\n",
      " [227 897]]\n",
      "Precision: 0.6152263374485597\n",
      "Recall: 0.7980427046263345\n",
      "F1 Score: 0.6948102246320682\n",
      "-----------------------\n",
      "Threshold: 0.4\n",
      "Confusion Matrix:\n",
      "[[859 453]\n",
      " [297 827]]\n",
      "Precision: 0.64609375\n",
      "Recall: 0.7357651245551602\n",
      "F1 Score: 0.6880199667221298\n",
      "-----------------------\n",
      "Threshold: 0.45\n",
      "Confusion Matrix:\n",
      "[[949 363]\n",
      " [368 756]]\n",
      "Precision: 0.675603217158177\n",
      "Recall: 0.6725978647686833\n",
      "F1 Score: 0.6740971912617031\n",
      "-----------------------\n",
      "Threshold: 0.5\n",
      "Confusion Matrix:\n",
      "[[1029  283]\n",
      " [ 435  689]]\n",
      "Precision: 0.7088477366255144\n",
      "Recall: 0.6129893238434164\n",
      "F1 Score: 0.6574427480916032\n",
      "-----------------------\n",
      "Threshold: 0.55\n",
      "Confusion Matrix:\n",
      "[[1100  212]\n",
      " [ 500  624]]\n",
      "Precision: 0.7464114832535885\n",
      "Recall: 0.5551601423487544\n",
      "F1 Score: 0.6367346938775511\n",
      "-----------------------\n",
      "Threshold: 0.6\n",
      "Confusion Matrix:\n",
      "[[1159  153]\n",
      " [ 586  538]]\n",
      "Precision: 0.7785817655571635\n",
      "Recall: 0.4786476868327402\n",
      "F1 Score: 0.5928374655647384\n",
      "-----------------------\n",
      "Threshold: 0.65\n",
      "Confusion Matrix:\n",
      "[[1204  108]\n",
      " [ 674  450]]\n",
      "Precision: 0.8064516129032258\n",
      "Recall: 0.400355871886121\n",
      "F1 Score: 0.5350772889417359\n",
      "-----------------------\n",
      "Threshold: 0.7\n",
      "Confusion Matrix:\n",
      "[[1239   73]\n",
      " [ 772  352]]\n",
      "Precision: 0.8282352941176471\n",
      "Recall: 0.31316725978647686\n",
      "F1 Score: 0.45448676565526147\n",
      "-----------------------\n",
      "Threshold: 0.75\n",
      "Confusion Matrix:\n",
      "[[1269   43]\n",
      " [ 865  259]]\n",
      "Precision: 0.8576158940397351\n",
      "Recall: 0.2304270462633452\n",
      "F1 Score: 0.36325385694249646\n",
      "-----------------------\n",
      "Threshold: 0.8\n",
      "Confusion Matrix:\n",
      "[[1288   24]\n",
      " [ 953  171]]\n",
      "Precision: 0.8769230769230769\n",
      "Recall: 0.152135231316726\n",
      "F1 Score: 0.25928733889310085\n",
      "-----------------------\n",
      "Threshold: 0.85\n",
      "Confusion Matrix:\n",
      "[[1301   11]\n",
      " [1015  109]]\n",
      "Precision: 0.9083333333333333\n",
      "Recall: 0.09697508896797152\n",
      "F1 Score: 0.17524115755627007\n",
      "-----------------------\n",
      "Threshold: 0.9\n",
      "Confusion Matrix:\n",
      "[[1308    4]\n",
      " [1073   51]]\n",
      "Precision: 0.9272727272727272\n",
      "Recall: 0.045373665480427046\n",
      "F1 Score: 0.08651399491094146\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.25, 0.3, 0.35, 0.40, 0.45, 0.5, 0.55, 0.60, 0.65, .70, .75, 0.8, 0.85, 0.9]\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = []\n",
    "    for i in range(len(y_prob_test)):\n",
    "        if y_prob_test[i] >= t:\n",
    "            preds.append(1.)\n",
    "        else:\n",
    "            preds.append(0.)\n",
    "    \n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    \n",
    "    print(f\"Threshold: {t}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9810ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold 0.25 for predictions: \n",
      " Profit: 139.7093333333334 \n",
      " Number of bets: 1847 \n",
      " Return %: 7.564121999639058 \n",
      "\n",
      "At threshold 0.3 for predictions: \n",
      " Profit: 159.76433333333335 \n",
      " Number of bets: 1658 \n",
      " Return %: 9.635967028548453 \n",
      "\n",
      "At threshold 0.35 for predictions: \n",
      " Profit: 161.61099999999996 \n",
      " Number of bets: 1458 \n",
      " Return %: 11.084430727023317 \n",
      "\n",
      "At threshold 0.4 for predictions: \n",
      " Profit: 175.05599999999998 \n",
      " Number of bets: 1280 \n",
      " Return %: 13.676249999999998 \n",
      "\n",
      "At threshold 0.45 for predictions: \n",
      " Profit: 154.776 \n",
      " Number of bets: 1119 \n",
      " Return %: 13.831635388739945 \n",
      "\n",
      "At threshold 0.5 for predictions: \n",
      " Profit: 146.9543333333334 \n",
      " Number of bets: 972 \n",
      " Return %: 15.118758573388211 \n",
      "\n",
      "At threshold 0.55 for predictions: \n",
      " Profit: 146.01433333333347 \n",
      " Number of bets: 836 \n",
      " Return %: 17.46582934609252 \n",
      "\n",
      "At threshold 0.6 for predictions: \n",
      " Profit: 128.82600000000002 \n",
      " Number of bets: 691 \n",
      " Return %: 18.643415340086833 \n",
      "\n",
      "At threshold 0.65 for predictions: \n",
      " Profit: 99.88833333333338 \n",
      " Number of bets: 558 \n",
      " Return %: 17.90113500597372 \n",
      "\n",
      "At threshold 0.7 for predictions: \n",
      " Profit: 64.27833333333338 \n",
      " Number of bets: 425 \n",
      " Return %: 15.124313725490207 \n",
      "\n",
      "At threshold 0.75 for predictions: \n",
      " Profit: 40.870000000000005 \n",
      " Number of bets: 302 \n",
      " Return %: 13.53311258278146 \n",
      "\n",
      "At threshold 0.8 for predictions: \n",
      " Profit: 18.913333333333327 \n",
      " Number of bets: 195 \n",
      " Return %: 9.699145299145295 \n",
      "\n",
      "At threshold 0.85 for predictions: \n",
      " Profit: 10.783333333333337 \n",
      " Number of bets: 120 \n",
      " Return %: 8.986111111111114 \n",
      "\n",
      "At threshold 0.9 for predictions: \n",
      " Profit: 4.475000000000004 \n",
      " Number of bets: 55 \n",
      " Return %: 8.136363636363644 \n",
      "\n",
      "(54.42666666666668, 50, 4, 100.79012345679016)\n",
      "(22.831258616248206, 1308, 1073, 0.9588936840087445)\n"
     ]
    }
   ],
   "source": [
    "validation_set = y_test.reset_index(drop = True)\n",
    "\n",
    "for t in [0.25, 0.3, 0.35, 0.40, 0.45, 0.5, 0.55, 0.60, 0.65, .70, .75, 0.8, 0.85, 0.9]:\n",
    "    results = get_profits(odds, y_prob_test, t, validation_set)\n",
    "    print(f\"At threshold {t} for predictions: \\n Profit: {results[0]} \\n Number of bets: {results[1]} \\n Return %: {results[2]} \\n\")\n",
    "\n",
    "print(get_value_strat1(odds, preds, 0.05, validation_set))\n",
    "print(get_value_strat2(odds, preds, 0.05, validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62a357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
